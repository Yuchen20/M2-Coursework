Search.setIndex({"alltitles": {"1. Multi-head Attention FLOPS": [[2, "1.-Multi-head-Attention-FLOPS"]], "2. RMSNorm FLOPS": [[2, "2.-RMSNorm-FLOPS"]], "3. Feed-Forward Network FLOPS": [[2, "3.-Feed-Forward-Network-FLOPS"]], "4. LoRA Adaptation FLOPS": [[2, "4.-LoRA-Adaptation-FLOPS"]], "5. Language Model Head FLOPS": [[2, "5.-Language-Model-Head-FLOPS"]], "6. Loss Calculation FLOPS": [[2, "6.-Loss-Calculation-FLOPS"]], "7. Residual Connection FLOPS": [[2, "7.-Residual-Connection-FLOPS"]], "API Reference": [[0, "api-reference"]], "Appendix: Additional Samples": [[1, "Appendix:-Additional-Samples"]], "Budget Planning Analysis": [[2, "Budget-Planning-Analysis"]], "Complete Preprocessing Pipeline with NumericalProcessor": [[1, "Complete-Preprocessing-Pipeline-with-NumericalProcessor"]], "Conclusion": [[1, "Conclusion"], [2, "Conclusion"]], "Data Module": [[0, "module-get_data"]], "Data Preparation": [[3, "Data-Preparation"], [5, "Data-Preparation"], [6, "Data-Preparation"]], "Dataset Overview": [[1, "Dataset-Overview"]], "Defining Operation Costs": [[2, "Defining-Operation-Costs"]], "Evaluating Fully Trained LLM Performance on Time Series Forecasting": [[6, null]], "Evaluating Trained LLM Performance on Time Series Forecasting": [[5, null]], "Evaluating Untrained LLM Performance on Time Series Forecasting": [[3, null]], "Experiment Pipeline": [[0, "experiment-pipeline"]], "Experiments": [[0, "module-experiment_initial"]], "FLOPS Calculator": [[0, "module-get_flops"]], "FLOPS Scaling with Different Parameters": [[2, "FLOPS-Scaling-with-Different-Parameters"]], "Flops Analysis": [[3, "Flops-Analysis"], [5, "Flops-Analysis"], [6, "Flops-Analysis"]], "Full Model FLOPS Breakdown": [[2, "Full-Model-FLOPS-Breakdown"]], "Improved LoRA Training": [[4, "Improved-LoRA-Training"]], "Indices and Tables": [[0, "indices-and-tables"]], "Installation and Setup": [[0, "installation-and-setup"]], "Interactive Visualization of Predator-Prey Dynamics": [[1, "Interactive-Visualization-of-Predator-Prey-Dynamics"]], "Introduction": [[3, "Introduction"]], "Jupyter Notebooks": [[0, null]], "Key Components": [[2, "Key-Components"]], "LLMTIME Preprocessing Scheme Implementation": [[1, "LLMTIME-Preprocessing-Scheme-Implementation"]], "LLMTIME String Representation": [[1, "LLMTIME-String-Representation"]], "LM Bias Weight Visualization": [[7, null]], "LoRA Weights Module": [[0, "module-lora_weights"]], "Lotka-Volterra Dataset Exploration & LLMTIME Preprocessing": [[1, null]], "Model Architecture Parameters": [[2, "Model-Architecture-Parameters"]], "Notebooks": [[0, "notebooks"]], "Potential Catastrophic Forgetting": [[3, "Potential-Catastrophic-Forgetting"]], "Preprocessor Module": [[0, "module-preprocessor"]], "Project Structure": [[0, "project-structure"]], "Results Analysis": [[3, "Results-Analysis"], [5, "Results-Analysis"], [6, "Results-Analysis"]], "Results and Findings": [[0, "results-and-findings"]], "Round-Trip Testing: Tokenize \u2192 Detokenize": [[1, "Round-Trip-Testing:-Tokenize-\u2192-Detokenize"]], "Scaling and Formatting": [[1, "Scaling-and-Formatting"]], "Time Series Forecasting with Qwen2.5-0.5B LLM": [[0, null]], "Tokenization Padding Methods": [[3, "Tokenization-Padding-Methods"]], "Tokenization with Qwen2.5 Tokenizer": [[1, "Tokenization-with-Qwen2.5-Tokenizer"]], "Train LoRA-LLM": [[4, null]], "Trainer Module": [[0, "module-Trainer"]], "Training the Model": [[4, "Training-the-Model"]], "Understanding FLOPS Calculation for Qwen2.5 Models": [[2, null]], "Zero-Shot Forecasting Evaluation": [[3, "Zero-Shot-Forecasting-Evaluation"], [5, "Zero-Shot-Forecasting-Evaluation"], [6, "Zero-Shot-Forecasting-Evaluation"]]}, "docnames": ["index", "notebooks/1_dataset_preprocess", "notebooks/2_flops_calculation", "notebooks/3_untrained_behaviour", "notebooks/4_train_lora_llm", "notebooks/5_initial_train_behaviour", "notebooks/6_fully_trained_behaviour", "notebooks/7_weight_visualize"], "envversion": {"nbsphinx": 4, "sphinx": 64, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1}, "filenames": ["index.rst", "notebooks\\1_dataset_preprocess.ipynb", "notebooks\\2_flops_calculation.ipynb", "notebooks\\3_untrained_behaviour.ipynb", "notebooks\\4_train_lora_llm.ipynb", "notebooks\\5_initial_train_behaviour.ipynb", "notebooks\\6_fully_trained_behaviour.ipynb", "notebooks\\7_weight_visualize.ipynb"], "indexentries": {"apply_lora() (in module experiment_final)": [[0, "experiment_final.apply_lora", false]], "apply_lora() (in module experiment_initial)": [[0, "experiment_initial.apply_lora", false]], "apply_lora() (in module lora_weights)": [[0, "lora_weights.apply_lora", false]], "clear_gpu_memory() (in module lora_weights)": [[0, "lora_weights.clear_gpu_memory", false]], "count_trainable_parameters() (in module lora_weights)": [[0, "lora_weights.count_trainable_parameters", false]], "datamaster (class in get_data)": [[0, "get_data.DataMaster", false]], "decode_to_string() (preprocessor.numericalprocessor method)": [[0, "preprocessor.NumericalProcessor.decode_to_string", false]], "decode_to_string() (trainer.loratrainer method)": [[0, "Trainer.LoRATrainer.decode_to_string", false]], "evaluate() (trainer.loratrainer method)": [[0, "Trainer.LoRATrainer.evaluate", false]], "evaluation_loop() (trainer.loratrainer method)": [[0, "Trainer.LoRATrainer.evaluation_loop", false]], "experiment_final": [[0, "module-experiment_final", false]], "experiment_initial": [[0, "module-experiment_initial", false]], "forward() (experiment_final.loralinear method)": [[0, "experiment_final.LoRALinear.forward", false]], "forward() (experiment_initial.loralinear method)": [[0, "experiment_initial.LoRALinear.forward", false]], "forward() (lora_weights.loralinear method)": [[0, "lora_weights.LoRALinear.forward", false]], "get_attention_flops() (get_flops.qwenflopscalculator method)": [[0, "get_flops.QwenFlopsCalculator.get_attention_flops", false]], "get_data": [[0, "module-get_data", false]], "get_data() (get_data.datamaster method)": [[0, "get_data.DataMaster.get_data", false]], "get_ffn_flops() (get_flops.qwenflopscalculator method)": [[0, "get_flops.QwenFlopsCalculator.get_ffn_flops", false]], "get_flops": [[0, "module-get_flops", false]], "get_flops() (get_flops.qwenflopscalculator method)": [[0, "get_flops.QwenFlopsCalculator.get_flops", false]], "get_lm_head() (get_flops.qwenflopscalculator method)": [[0, "get_flops.QwenFlopsCalculator.get_LM_head", false]], "get_lora_flops() (get_flops.qwenflopscalculator method)": [[0, "get_flops.QwenFlopsCalculator.get_lora_flops", false]], "get_loss_flops() (get_flops.qwenflopscalculator method)": [[0, "get_flops.QwenFlopsCalculator.get_loss_flops", false]], "get_residual_flops() (get_flops.qwenflopscalculator method)": [[0, "get_flops.QwenFlopsCalculator.get_residual_flops", false]], "get_rmsnorm_flops() (get_flops.qwenflopscalculator method)": [[0, "get_flops.QwenFlopsCalculator.get_RMSNorm_flops", false]], "is_world_process_zero() (trainer.loratrainer method)": [[0, "Trainer.LoRATrainer.is_world_process_zero", false]], "load_checkpoint() (in module lora_weights)": [[0, "lora_weights.load_checkpoint", false]], "load_checkpoint() (trainer.loratrainer method)": [[0, "Trainer.LoRATrainer.load_checkpoint", false]], "load_qwen() (in module experiment_final)": [[0, "experiment_final.load_qwen", false]], "load_qwen() (in module experiment_initial)": [[0, "experiment_initial.load_qwen", false]], "load_qwen() (in module lora_weights)": [[0, "lora_weights.load_qwen", false]], "log_flops() (get_flops.qwenflopscalculator method)": [[0, "get_flops.QwenFlopsCalculator.log_flops", false]], "log_flops_to_wandb() (trainer.loratrainer method)": [[0, "Trainer.LoRATrainer.log_flops_to_wandb", false]], "log_gradient_stats() (trainer.loratrainer method)": [[0, "Trainer.LoRATrainer.log_gradient_stats", false]], "lora_weights": [[0, "module-lora_weights", false]], "loralinear (class in experiment_final)": [[0, "experiment_final.LoRALinear", false]], "loralinear (class in experiment_initial)": [[0, "experiment_initial.LoRALinear", false]], "loralinear (class in lora_weights)": [[0, "lora_weights.LoRALinear", false]], "loratrainer (class in trainer)": [[0, "Trainer.LoRATrainer", false]], "lotkavolterradataset (class in get_data)": [[0, "get_data.LotkaVolterraDataset", false]], "merge() (experiment_final.loralinear method)": [[0, "experiment_final.LoRALinear.merge", false]], "merge() (experiment_initial.loralinear method)": [[0, "experiment_initial.LoRALinear.merge", false]], "merge() (lora_weights.loralinear method)": [[0, "lora_weights.LoRALinear.merge", false]], "merge_lora_weights() (in module lora_weights)": [[0, "lora_weights.merge_lora_weights", false]], "merge_lora_weights() (trainer.loratrainer method)": [[0, "Trainer.LoRATrainer.merge_lora_weights", false]], "module": [[0, "module-Trainer", false], [0, "module-experiment_final", false], [0, "module-experiment_initial", false], [0, "module-get_data", false], [0, "module-get_flops", false], [0, "module-lora_weights", false], [0, "module-preprocessor", false], [0, "module-sweep", false], [0, "module-sweep_context_length", false]], "numericalprocessor (class in preprocessor)": [[0, "preprocessor.NumericalProcessor", false]], "operationflops (class in get_flops)": [[0, "get_flops.OperationFlops", false]], "postprocess() (preprocessor.numericalprocessor method)": [[0, "preprocessor.NumericalProcessor.postprocess", false]], "preprocess() (preprocessor.numericalprocessor method)": [[0, "preprocessor.NumericalProcessor.preprocess", false]], "preprocessor": [[0, "module-preprocessor", false]], "qwenflopscalculator (class in get_flops)": [[0, "get_flops.QwenFlopsCalculator", false]], "save_checkpoint() (trainer.loratrainer method)": [[0, "Trainer.LoRATrainer.save_checkpoint", false]], "setup_lora_model() (in module lora_weights)": [[0, "lora_weights.setup_lora_model", false]], "sweep": [[0, "module-sweep", false]], "sweep_context_length": [[0, "module-sweep_context_length", false]], "test() (trainer.loratrainer method)": [[0, "Trainer.LoRATrainer.test", false]], "train() (trainer.loratrainer method)": [[0, "Trainer.LoRATrainer.train", false]], "train_model() (in module experiment_final)": [[0, "experiment_final.train_model", false]], "train_model() (in module experiment_initial)": [[0, "experiment_initial.train_model", false]], "train_step() (trainer.loratrainer method)": [[0, "Trainer.LoRATrainer.train_step", false]], "trainer": [[0, "module-Trainer", false]], "unmerge() (experiment_final.loralinear method)": [[0, "experiment_final.LoRALinear.unmerge", false]], "unmerge() (experiment_initial.loralinear method)": [[0, "experiment_initial.LoRALinear.unmerge", false]], "unmerge() (lora_weights.loralinear method)": [[0, "lora_weights.LoRALinear.unmerge", false]], "unmerge_lora_weights() (in module lora_weights)": [[0, "lora_weights.unmerge_lora_weights", false]], "unmerge_lora_weights() (trainer.loratrainer method)": [[0, "Trainer.LoRATrainer.unmerge_lora_weights", false]]}, "objects": {"": [[0, 0, 0, "-", "Trainer"], [0, 0, 0, "-", "experiment_final"], [0, 0, 0, "-", "experiment_initial"], [0, 0, 0, "-", "get_data"], [0, 0, 0, "-", "get_flops"], [0, 0, 0, "-", "lora_weights"], [0, 0, 0, "-", "preprocessor"], [0, 0, 0, "-", "sweep"], [0, 0, 0, "-", "sweep_context_length"]], "Trainer": [[0, 1, 1, "", "LoRATrainer"]], "Trainer.LoRATrainer": [[0, 2, 1, "", "decode_to_string"], [0, 2, 1, "", "evaluate"], [0, 2, 1, "", "evaluation_loop"], [0, 2, 1, "", "is_world_process_zero"], [0, 2, 1, "", "load_checkpoint"], [0, 2, 1, "", "log_flops_to_wandb"], [0, 2, 1, "", "log_gradient_stats"], [0, 2, 1, "", "merge_lora_weights"], [0, 2, 1, "", "save_checkpoint"], [0, 2, 1, "", "test"], [0, 2, 1, "", "train"], [0, 2, 1, "", "train_step"], [0, 2, 1, "", "unmerge_lora_weights"]], "experiment_final": [[0, 1, 1, "", "LoRALinear"], [0, 3, 1, "", "apply_lora"], [0, 3, 1, "", "load_qwen"], [0, 3, 1, "", "train_model"]], "experiment_final.LoRALinear": [[0, 2, 1, "", "forward"], [0, 2, 1, "", "merge"], [0, 2, 1, "", "unmerge"]], "experiment_initial": [[0, 1, 1, "", "LoRALinear"], [0, 3, 1, "", "apply_lora"], [0, 3, 1, "", "load_qwen"], [0, 3, 1, "", "train_model"]], "experiment_initial.LoRALinear": [[0, 2, 1, "", "forward"], [0, 2, 1, "", "merge"], [0, 2, 1, "", "unmerge"]], "get_data": [[0, 1, 1, "", "DataMaster"], [0, 1, 1, "", "LotkaVolterraDataset"]], "get_data.DataMaster": [[0, 2, 1, "", "get_data"]], "get_flops": [[0, 1, 1, "", "OperationFlops"], [0, 1, 1, "", "QwenFlopsCalculator"]], "get_flops.QwenFlopsCalculator": [[0, 2, 1, "", "get_LM_head"], [0, 2, 1, "", "get_RMSNorm_flops"], [0, 2, 1, "", "get_attention_flops"], [0, 2, 1, "", "get_ffn_flops"], [0, 2, 1, "", "get_flops"], [0, 2, 1, "", "get_lora_flops"], [0, 2, 1, "", "get_loss_flops"], [0, 2, 1, "", "get_residual_flops"], [0, 2, 1, "", "log_flops"]], "lora_weights": [[0, 1, 1, "", "LoRALinear"], [0, 3, 1, "", "apply_lora"], [0, 3, 1, "", "clear_gpu_memory"], [0, 3, 1, "", "count_trainable_parameters"], [0, 3, 1, "", "load_checkpoint"], [0, 3, 1, "", "load_qwen"], [0, 3, 1, "", "merge_lora_weights"], [0, 3, 1, "", "setup_lora_model"], [0, 3, 1, "", "unmerge_lora_weights"]], "lora_weights.LoRALinear": [[0, 2, 1, "", "forward"], [0, 2, 1, "", "merge"], [0, 2, 1, "", "unmerge"]], "preprocessor": [[0, 1, 1, "", "NumericalProcessor"]], "preprocessor.NumericalProcessor": [[0, 2, 1, "", "decode_to_string"], [0, 2, 1, "", "postprocess"], [0, 2, 1, "", "preprocess"]]}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "function", "Python function"]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:function"}, "terms": {"": [0, 1, 2, 3, 4, 5, 6, 7], "0": [1, 2, 3, 4, 5, 6, 7], "00": [1, 3, 4, 5, 6], "000": 6, "0000": 1, "0001": 0, "00011165": 6, "000129": 1, "000177": 1, "00028014": 6, "000292": 1, "00046078": 6, "00079776": 6, "001": 6, "001045": 1, "00107841": 5, "001104": 1, "001240": 1, "001382": 1, "001646": 1, "0017915": 6, "00179791": 6, "001834": 1, "00195198": 6, "002": 0, "0020": 0, "002024": 6, "0021": 1, "002107": 1, "002167": 1, "0023": 5, "002432": 1, "002484": 1, "0025": 6, "002506": 1, "00255047": 5, "002771": 6, "0028": 0, "003002": 1, "003090": 1, "00313302": 6, "003230": 1, "003292": 1, "0035": 6, "003642": 1, "003700": 1, "003711": 1, "00371928": 6, "003779": 1, "0039": 5, "0041": 5, "0044": 5, "004565": 1, "0045652": 1, "00462363": 6, "0047": 5, "00507598": 3, "0051": 6, "0053": 6, "0054137": 1, "00563559": 5, "00587416": 6, "0060": 6, "00603702": 6, "00698984": 5, "007071": 1, "00725995": 6, "0074": 5, "00767334": 3, "0079": 6, "008": [5, 6], "0089": 5, "008e": 6, "0092198": 6, "0093": 5, "00985967": 5, "01": [0, 3, 5, 6], "0111": 6, "01158123": 6, "0119": 5, "012": [5, 6], "0127": 6, "0139": 5, "0143": 6, "0157": 6, "016": 6, "01613979": 6, "01625338": 5, "01629537": 6, "0167": 5, "0172": [5, 6], "01835747": 5, "019064": 6, "0191": 0, "01942525": 6, "01961915": 3, "0198": 6, "01it": 5, "01x": 2, "02": [1, 4], "02033901": 6, "0204": 5, "0208": 6, "021": 2, "0223": 6, "023": 3, "02332672": 6, "02352411": 5, "023984": 6, "0240": 0, "0244": 6, "024680": 1, "02554441": 6, "0263": [0, 5], "026321": 6, "0265": 6, "0269": 5, "02780316": 5, "02833716": 3, "029675": 5, "0297": 0, "02it": [3, 5], "03": [1, 4], "030001": 1, "03027051": 5, "031105": 1, "0311053": 1, "03112968": 6, "0318": 5, "0321": 5, "03215603902935982": 4, "0322": 4, "03231214": 3, "03273133": 6, "0330": 6, "0334": 6, "03351163": 3, "0337": 5, "0344": 5, "0347": 6, "036": 2, "0361": 6, "0362": 0, "036210": 5, "037": 3, "0371": 6, "038": 2, "03801932": 6, "038790": 1, "03913796": 5, "03923728": 5, "039777": 1, "03it": [5, 6], "04": [1, 3, 4], "040": 5, "04010308": 6, "04019548": 6, "0402": 6, "040624": 1, "0412": 6, "0417": 6, "042": [5, 6], "0424": 5, "04241317": 5, "0426": 6, "0428": 6, "043": 2, "0441": 6, "0449815": 3, "0452": 6, "0458": 6, "0471": 5, "04772122": 3, "04845199": 5, "04it": 5, "05": [3, 4], "0504": 5, "0524": 6, "05279313": 5, "05341527611017227": 4, "054": 5, "056": 2, "0587": 5, "06": [3, 4], "060": 2, "061": [5, 6], "06242362": 5, "064": 2, "065": 3, "0651": 0, "065142": 5, "06644831": 6, "068": 2, "06817318": 3, "06946652": 6, "069979": 3, "06it": 3, "07": [3, 4, 5], "070": 3, "0700": 0, "0705": 6, "0717": 5, "072": 2, "072551": 6, "0726": 0, "0732226": 1, "07586795": 3, "076": 2, "0772": 6, "0787003": 1, "07991088926792145": 4, "07it": [3, 5], "08": 3, "08084267": 5, "0809": 6, "083372": 5, "0834": 0, "08616945": 5, "08743417": 5, "08795378": 5, "08936435": 3, "08it": 5, "09028841": 5, "09158203": 3, "094": 3, "09535234": 3, "096": 2, "09666347": 5, "097": [2, 5], "0973": 6, "0996622": 6, "0f": [2, 3, 5, 6], "1": [0, 1, 3, 4, 5, 6, 7], "10": [0, 1, 2, 3, 4, 5, 6], "100": [0, 1, 3, 4, 5, 6, 7], "1000": [0, 1], "10000": [5, 6], "102": [1, 2], "1025808279440": 5, "103391228": 5, "103918336": 2, "1048": 0, "104814": 3, "10866642": 3, "109": 6, "1095": 5, "10th": 6, "11": [1, 3, 4], "110": 2, "1113": 4, "11131727695465088": 4, "11168491": 5, "112374844497": 6, "11277984829": 6, "112855": 1, "113": 2, "114": 2, "115": 2, "1158321771": 5, "116": 5, "116683": 3, "1167": 0, "116e": 5, "11835846": 5, "11it": [3, 4], "12": [1, 2, 3, 4, 5, 6, 7], "120": 2, "12000": 6, "121": 2, "12132": 5, "121e": [5, 6], "123": 2, "1257": 6, "1267944432769": 6, "1275676": 5, "12789576988279286896": 6, "128": [0, 2, 3, 5, 6], "129": 2, "1290396828": 6, "12it": 6, "13": [1, 2, 3, 5, 6], "131": 2, "13250503": 3, "134": [2, 6], "134e": 6, "135": 2, "13527314253": 5, "135554": 5, "1356": 0, "13611017": 6, "13777865725529": 6, "139472218": 6, "13it": [3, 6], "14": [1, 2, 3, 4, 5, 6, 7], "140": 2, "1400x1500": 7, "14351271": 3, "1437386": 5, "144": 2, "149078689276495": 6, "14912029": 3, "149608997834": 5, "15": [1, 2, 3, 5, 6, 7], "150": [1, 2], "150664": 1, "150884": 3, "1509": 0, "15162688": 6, "151643": 3, "151936": 2, "15266742": 5, "153": 1, "15436463": 1, "154365": 1, "155": 2, "15549632906913757": 4, "15815355": 3, "15818435": 5, "158594": 1, "159": 5, "15it": 6, "16": [1, 2, 3, 5, 6, 7], "160": 2, "1604": [3, 5, 6], "161886": 1, "16188619": 1, "16210063752722528": 6, "16215265596896896": 5, "16216687344171552": 3, "162235": 1, "16223547": 1, "164": 2, "165762384778345426": 6, "1659807433122": 5, "166870": 5, "17": [1, 2, 3, 4, 5, 6], "170": 7, "170290265": 5, "171": 2, "173": 2, "1746": 0, "174634": 5, "1794": 5, "1794094622643868": 6, "1799038": 6, "17it": 5, "18": [1, 2, 4, 5, 7], "180": 3, "181563": 1, "1819341778755188": 4, "182383": 1, "18486528": 3, "185": 2, "186162": 1, "18616238": 1, "187": 2, "189": 2, "18it": 4, "19": [1, 3, 4, 5], "192": 2, "19397523": 3, "194667": 1, "19590111": 5, "196": 2, "197": 6, "1972972840": 5, "197925": 1, "1990": 4, "19it": [5, 6], "1e": [0, 3, 5, 6], "1e16": [3, 5, 6], "1e17": [0, 2, 3, 5, 6], "1f77b4": [3, 5, 6], "2": [0, 1, 3, 4, 5, 6, 7], "20": [1, 3, 4, 5, 6], "200": [0, 1, 3, 5, 6], "20087": 5, "2013": 3, "2015": 5, "20164469": 3, "2020": 3, "2021": 3, "2023": 3, "20250321_193006": 4, "204": [1, 3], "204152": 1, "204592": 1, "20610": 5, "208": 4, "20864": 3, "20928374579678978": 6, "20957": 3, "21": [1, 3, 4, 5, 6], "21137": 5, "21150": 5, "21340": 5, "21372": 3, "21374": 3, "2145925": 5, "21490975": 3, "21503": 6, "21522": 6, "21542": 5, "21575": 5, "21636": 6, "21652": 6, "21758": 5, "21764": 6, "21767": 3, "21798": 6, "218": 2, "2184": 6, "21841423095": 5, "21856": 5, "219": 3, "219088": 6, "21939": 6, "22": [1, 3, 5], "220": 2, "22034": 6, "22041": 5, "22060": 6, "22092": 6, "22097": 5, "22268": 5, "22344": 6, "22419": 6, "22479": 5, "22544": 5, "22576": 6, "22628": 3, "22683": 5, "22795": 6, "22837": 6, "22891": 3, "22897": 5, "229": 2, "22901": 5, "22915": 5, "22916": 6, "22976": 5, "22983165": 1, "229832": 1, "229961": 1, "22it": 5, "23": [1, 3, 5], "230": 2, "23050": 5, "23054": 5, "23069": 5, "23080": 6, "23088": 6, "23128": 5, "23140": 6, "23158": 6, "23164": 5, "23197": 5, "23203": 5, "23216": 5, "23236": 5, "23249": 6, "23297": 5, "23300": 6, "23312": 3, "23316": 3, "23331": 6, "23333": 3, "23348": 3, "23355": 3, "23387": 5, "23402": 5, "23408": 6, "23430": 3, "23446": 6, "234766": 1, "23481": 6, "23487": 5, "23514": 3, "23548": 6, "23558": 3, "23590": 5, "23624": 6, "23627": [3, 5], "23666": 3, "23708": 3, "23749": 6, "23751": 6, "23760": [5, 6], "23805": 6, "23829": 3, "23877": 5, "23886": 6, "23930": 6, "23933": 6, "23936": 3, "23951": 5, "23956": 5, "23988": 5, "24": [1, 2, 3, 5, 6], "240": 2, "24010": 6, "24020": 3, "24026": 6, "24046": 5, "24076": 6, "24111": 6, "241190157925": 5, "24139": 3, "24143": 3, "24168": 3, "24171": 6, "24202": 5, "24209": 5, "24245": 6, "24257": 5, "24266": 6, "24274382": 5, "24279": 6, "24283": 5, "24345913": 5, "24507": 3, "24523": 6, "248": 2, "24it": [5, 6], "25": [2, 4, 5, 6], "252": 3, "255": 1, "256": [0, 2], "256868583835676824": 6, "257": 2, "258": 5, "25it": [3, 6], "26": [1, 2, 3, 5, 6], "260": [3, 5, 6], "260821": 1, "260828": 1, "261083": 1, "262": 2, "2629277": 1, "262928": 1, "2630726": 3, "266": 2, "266840": 1, "268457": 5, "2685727999782": 5, "269": 2, "27": [1, 2, 5, 6], "270": [2, 4], "272": 2, "27217925": 3, "273680504": 5, "278": 2, "28": [2, 3, 5], "280": 2, "281": 2, "2865": 5, "289837": 1, "29": [1, 2, 5], "291e": [5, 6], "2934": 5, "29it": [3, 6], "2ca02c": [3, 5, 6], "2f": [1, 2, 3, 5, 6, 7], "3": [0, 1, 3, 4, 5, 6, 7], "30": [1, 2, 5, 7], "300": [2, 3, 5, 6], "3000": 0, "300283": 1, "30028325": 1, "30060": 7, "301328": 1, "308": 2, "30993408": 2, "31": [1, 3, 5, 6], "310": 2, "31000320": 2, "31003392": 2, "31131": 7, "312": 2, "3122903631": 5, "312313": 1, "31240": 6, "31it": [3, 5, 6], "32": [2, 5, 6], "3200": [3, 5, 6], "32343552": 2, "32350720": 2, "32354304": 2, "325": 6, "325e": 6, "326": 3, "32619426": 3, "326e": 3, "327": [2, 5], "327e": 5, "32it": 5, "33": [3, 5, 6], "33208": 5, "33536": 7, "336": [2, 4], "33954135": 5, "33it": [3, 5, 6], "34": [3, 4, 5, 6], "3421573": 5, "342673": 3, "3427": 0, "343": 2, "344": 2, "34556928": 2, "34557184": 2, "34557312": 2, "34565120": 2, "34565376": 2, "34565504": 2, "34569728": 2, "34it": 5, "35": 1, "352": 2, "35368737348": 5, "3557232766292493542": 6, "356": 2, "35665712": 5, "35it": 3, "36": [3, 5, 6], "365": 2, "369": 2, "36it": 5, "37": 5, "370": 2, "37468666": 3, "375": 2, "378682": 1, "37it": 5, "38": [1, 3, 4], "382374439369": 6, "384": [3, 6], "38444456323": 6, "384e": 6, "385": 3, "385e": 3, "386": 5, "386e": 5, "388": 2, "38it": 5, "39": [1, 3, 4, 5, 6], "391799155757": 5, "3929024798": 6, "393": 2, "39512656": 5, "3968": 6, "397": [3, 5], "398": 2, "39it": [3, 5], "3_untrained_behaviour": [5, 6], "3e": [3, 5, 6], "3f": [3, 5, 6], "3rd": 3, "4": [0, 1, 3, 4, 5, 6, 7], "40": [2, 3, 5, 6], "400": [2, 3, 5, 6], "4004": 4, "401": 6, "404414": 1, "40519": 7, "407644": 1, "40764433": 1, "408": 3, "411504": 3, "418": [2, 5], "419": 6, "4192963848494": 6, "41it": [3, 6], "42": [3, 4, 5, 6], "424": 2, "428836880": 6, "42it": [3, 6], "43": [3, 6], "43455353": 5, "434924": 1, "43it": [3, 6], "44": [3, 6], "4418": 4, "443970763": 5, "445332": 5, "44it": [3, 5, 6], "45": [3, 6, 7], "451": 2, "452": 2, "45248698837968575950": 6, "456": 2, "45858298248388": 6, "45it": [3, 5], "46": 3, "460": 2, "4612": 4, "4634": 5, "468": 2, "46956488": 6, "47": 3, "47306427": 3, "476": 2, "477": 2, "478": 4, "47it": 5, "48": 6, "481": 2, "4864": 2, "48it": 5, "49": [5, 6], "490": 4, "492": 2, "494": 2, "49it": [3, 5, 6], "4f": [1, 7], "5": [3, 4, 5, 6, 7], "50": [1, 3, 4, 5, 6], "500": [0, 5, 6], "501": 6, "501e": 6, "502": 5, "502e": 5, "5047": 4, "506": 3, "506e": 3, "508": 2, "50it": 6, "51": 1, "510": 2, "512": [0, 2, 3, 4, 5, 6], "514073": 1, "514995738653079": 6, "516": 2, "5160": 6, "5178472": 6, "519": 2, "5191205411": 5, "52": [3, 6], "521642": 1, "5218158": 1, "5228817": 1, "522882": 1, "525": 2, "526": 2, "53": 3, "532": 2, "5343": 4, "53635156": 1, "537": 2, "53it": 6, "54": 3, "544": 2, "545": 2, "547e": 3, "54it": 3, "55": 3, "5510": 0, "551002": 3, "55291": 5, "55306584": 1, "5587592": 5, "55it": [3, 5], "56": [1, 3], "561392": 1, "563008": 1, "564": 2, "564390": 1, "56439036": 1, "567": 2, "568": 2, "5696": 1, "56it": [3, 5, 6], "57": [2, 3], "57120160743": 5, "572": 2, "57it": [5, 6], "58": 2, "582": 2, "584": 2, "58it": [3, 6], "59": [1, 3], "592": 2, "592657": 1, "59312147": 1, "596e": [3, 5], "5b": [1, 2, 3, 4, 5, 6, 7], "6": [0, 1, 3, 4, 5, 6], "60": [1, 4, 5, 6], "600": 2, "601798": 1, "603e": 6, "605509": 1, "6055092": 1, "60it": 6, "61": [2, 5], "6189577536396998": 6, "61it": 5, "62": [3, 5], "620": 2, "6268": 6, "6285472": 3, "629": [5, 6], "62it": 6, "63": 2, "630": 2, "633999153682": 5, "636": 2, "63878571": 5, "639": 2, "63it": [3, 5, 6], "64": 2, "640": 2, "648": 2, "64it": [3, 5, 6], "65": 3, "655": 2, "65533": 7, "656": 5, "656e": 5, "658342": 6, "65it": [5, 6], "67": 2, "670": 6, "670e": 6, "672": 2, "676": 5, "68": 3, "680": 2, "681954": 1, "6822457": 1, "682246": 1, "685": 2, "6863802": 1, "688": 2, "68it": [3, 4, 6], "6946": 5, "6981": 1, "69it": [5, 6], "6f": [1, 3, 5, 6], "7": [0, 1, 3, 4, 5, 6, 7], "70823574": 1, "70it": 6, "71": 1, "711743": 1, "713672": 1, "714651068": 5, "716674": 1, "7166742": 1, "71it": 5, "72": 6, "720": 2, "724": 2, "72it": [5, 6], "731": 2, "737461": 1, "73it": 6, "74": [5, 7], "740": 2, "7401": 1, "740551": 1, "74055135": 1, "742": 2, "74it": 6, "75": 4, "750": 2, "7503": 5, "75397625930299864": 6, "756c": 7, "758": 2, "765": 2, "768": [0, 2, 3, 5, 6], "7681343": 1, "7685": 1, "7687197": 1, "770243": 5, "772": 2, "7758": 3, "776": 2, "777110": 1, "7795419": 1, "779542": 1, "77it": 3, "78": 5, "780": 2, "78it": 6, "796": 2, "799b": 7, "79it": 6, "7it": 4, "8": [0, 1, 2, 3, 4, 5, 6, 7], "80": 4, "800": [3, 5, 6], "80288": 6, "804": [3, 5, 6], "8040001": 3, "81": 4, "811": 2, "81it": 5, "82": 4, "82180643": 1, "824": 2, "824511": 1, "82451135": 1, "824688": 1, "825": 2, "82it": 5, "8300": 7, "8314108842": 5, "8349962": 1, "836": 2, "838": 2, "83it": [5, 6], "84": [3, 4], "844": 2, "84it": 6, "8540631": 1, "85it": [5, 6], "86": [1, 5], "860368": 1, "8605354": 1, "862": 2, "86it": 5, "874566685": 7, "8888": 0, "88it": [3, 5], "892": 2, "896": 2, "9": [1, 2, 3, 5, 6, 7], "90": 1, "9001321": 1, "903786": 1, "9079171": 5, "90it": [3, 5], "91": [2, 6], "91579": 5, "919": 2, "91it": 5, "92": [5, 6, 7], "921": 2, "92488897091": 5, "929777877534784428": 6, "92it": 6, "93": [1, 3, 5, 6], "93179136": 2, "932": 2, "933897": 1, "936": 2, "93it": 6, "94": 3, "944": 2, "949917": 1, "94991744": 1, "95": [5, 7], "951563": 1, "95it": 6, "96": [3, 5, 6], "966": 2, "967e": [3, 5], "969": 6, "97": [4, 6], "9714744": 1, "97247232": 2, "979": 2, "98": [1, 3, 5, 6], "983067": 1, "989": 2, "98it": 6, "99": [1, 5], "99it": 6, "9e47": 7, "A": [0, 3, 4, 5, 6], "And": [3, 5, 6], "As": [3, 5, 6], "But": [3, 5, 6], "By": 5, "For": [2, 3, 4, 5, 6], "If": [0, 3, 5, 6], "In": [3, 4, 5, 6, 7], "It": [3, 4, 5, 6], "No": 3, "Of": [3, 5, 6], "One": [3, 5], "That": [3, 5, 6], "The": [0, 1, 2, 3, 4, 5, 6, 7], "Their": [5, 6], "There": [0, 5, 6], "These": [1, 3, 5, 6, 7], "To": [2, 3, 5, 6], "Will": 6, "With": [3, 5, 6], "_": [2, 3, 5, 6], "__dict__": 2, "__init__": [4, 5, 6], "__name__": [1, 3, 4, 5, 6], "_ab": [0, 2], "_add": [0, 2], "_co": [0, 2], "_core": 4, "_div": [0, 2], "_exp": [0, 2], "_instanc": [3, 4, 5, 6], "_inv": [0, 2], "_log": [0, 2], "_mul": [0, 2], "_neg": [0, 2], "_per_tim": [3, 5, 6], "_per_token": [3, 5, 6], "_relu": [0, 2], "_sin": [0, 2], "_sqrt": [0, 2], "_sub": [0, 2], "_to_str": 1, "a_": 6, "a_1": [3, 6], "a_2": 6, "a_3": 6, "a_4": 6, "a_5": 6, "a_6": 6, "a_n": [3, 6], "aaaaaa": 7, "ab": [1, 2, 3, 5, 6], "about": [3, 4, 5, 6, 7], "abov": [1, 3, 5, 6], "absolut": [0, 1, 2, 3, 5, 6], "abspath": [2, 3, 4, 5, 6], "absurd": 3, "accept": 4, "access": [3, 4, 5, 6], "accord": 1, "account": [2, 3, 5, 6], "accumul": [3, 5, 6], "accur": [0, 2, 3, 5, 6], "accuraci": [3, 5, 6], "achiev": 5, "acquir": 3, "across": [0, 2, 3, 5, 6], "activ": [0, 2], "actual": [3, 4, 5, 6], "ad": [1, 2, 4, 5, 6], "adapt": [0, 3, 4, 5, 6], "add": [0, 1, 2, 3, 4, 5, 6, 7], "add_generation_prompt": [5, 6], "add_safe_glob": 4, "addit": [0, 2, 3, 6], "addition": [3, 5, 6], "adher": 2, "adjust": 3, "adventur": [3, 6], "affect": [0, 3, 5, 6], "afford": 2, "after": [0, 3, 4, 5, 6], "afterward": 0, "again": [3, 5, 6], "against": 6, "aggreg": [3, 5, 6], "ah": 5, "ahead": [0, 3, 6], "ai": 4, "aim": [3, 5, 6], "air": [5, 6], "al": 3, "alibaba": [5, 6], "align": 5, "aliv": 3, "all": [0, 1, 3, 4, 5, 6, 7], "all_valu": 1, "alli": 6, "allow": [1, 2, 3, 4, 5, 6], "allowlist": 4, "alon": 5, "alpha": [0, 1, 3, 4, 5, 6, 7], "alreadi": [1, 3, 5, 6], "also": [3, 4, 5, 6], "altern": 4, "although": [0, 3], "alv": 3, "alwai": [3, 6], "am": 6, "amaz": 3, "amount": [3, 5, 6], "amp": [1, 5], "an": [0, 1, 2, 3, 4, 5, 6], "analysi": [0, 1], "analyz": [0, 2], "anew": [3, 5], "ani": [3, 5, 6], "annot": 7, "anoth": [3, 5, 6], "answer": [3, 5, 6], "anyth": 3, "api": 4, "appdata": 7, "appeal": 1, "appear": [1, 5], "append": [1, 2, 3, 4, 5, 6], "appendix": 0, "appli": [0, 1, 2, 3, 4, 5, 6], "applic": 2, "apply_chat_templ": [5, 6], "apply_lora": [0, 5, 6], "appreci": [3, 5], "approach": [1, 3, 5, 6], "appropri": [1, 3, 5, 6], "approx": 6, "approxim": [1, 3, 5, 6], "ar": [0, 2, 3, 4, 5, 6, 7], "arang": 7, "arbitrari": 4, "architectur": 0, "arg": [], "argmax": [3, 5, 6], "argsort": 7, "argument": 4, "arial": 7, "arithmet": [3, 5, 6], "around": [5, 6], "arrai": [0, 3, 5, 6], "arrow": 1, "arrow_indic": 1, "ascend": 2, "ask": 5, "aspir": 6, "assert": [3, 4, 5, 6], "assertionerror": 0, "assess": 3, "assist": [5, 6], "astyp": 1, "ate": 3, "attent": [0, 3, 4, 5, 6], "attention_breakdown": 2, "attention_dim": 2, "attention_flop": 2, "attr_nam": 2, "attr_valu": 2, "automodelforcausallm": [3, 4, 5, 6], "autoregress": [3, 5, 6], "autotoken": [1, 3, 4, 5, 6, 7], "averag": [3, 5, 6], "awai": [3, 5], "ax": [2, 3, 5, 6, 7], "ax1": [3, 5, 6, 7], "ax2": [3, 5, 6, 7], "ax3": 7, "axhlin": 7, "axi": [2, 3, 5, 6], "axomsmwz": 4, "axvlin": 7, "b": [2, 4, 5, 6], "back": [0, 1, 2, 3, 5, 6], "backend": 4, "background": 2, "backward": [0, 2], "bad": 3, "balanc": [3, 5, 6], "bar": 7, "base": [0, 1, 2, 3, 5, 6], "base_out": [4, 5, 6], "baselin": [0, 3, 5, 6], "basic": [1, 6], "basket": 3, "batch": [0, 2, 3], "batch_decod": [3, 5, 6], "batch_siz": [0, 2, 3, 4, 5, 6], "bbox": 7, "beacon": [3, 6], "beat": [5, 6], "beauti": [1, 3, 5, 6], "becaus": [3, 5, 6], "becom": [5, 6], "been": 4, "befor": [2, 3, 4, 6], "begin": [3, 5, 6], "behavior": [0, 1, 2], "behind": [5, 6], "behold": 6, "being": [5, 6], "below": [0, 1, 3, 5, 6], "benefit": 4, "berri": 6, "best": [0, 1, 2, 4], "better": [2, 3, 4, 5, 6], "between": [0, 1, 2, 3, 5, 6], "bewar": 3, "beyond": [5, 6], "bia": [0, 3, 4, 5, 6], "bias": [4, 7], "bias_tensor": 7, "big": 3, "bin": [0, 1, 7], "bird": 3, "birdsong": 5, "black": 7, "blend": 6, "bless": 6, "blue": [1, 2, 3, 5, 6], "bold": [1, 3, 5, 6], "bool": 0, "born": 5, "both": [1, 2, 3, 5, 6], "bottom": [3, 5, 6], "bound": 5, "box": [3, 5, 6], "boxstyl": 7, "brain": [4, 7], "break": [3, 5, 6], "breakdown": 0, "breakdown_str": 0, "breath": [5, 6], "breez": 5, "bridg": 1, "bright": [3, 5, 6], "brighter": 3, "bring": [3, 6], "broccoli": 3, "budget": [0, 3, 5, 6], "build": [0, 3, 5, 6], "burn": 3, "butterfli": [3, 5], "bytes_io": 7, "b\u0101ng": 5, "c": [4, 7], "calcul": [1, 3, 5, 6], "call": [0, 5, 6], "cam": [4, 7], "cambridg": 4, "can": [2, 3, 4, 5, 6, 7], "canina": 5, "canopi": 5, "canva": [5, 7], "capabl": [3, 5, 6], "captur": [3, 5], "care": [0, 3], "carefulli": [3, 5, 6], "carnat": 5, "carri": 5, "cast": 5, "cat": [3, 5, 6], "catastroph": 0, "ce": [3, 4, 5, 6], "ce_": [3, 5, 6], "ce_128_per_token": [3, 5, 6], "celebr": 6, "cell": [5, 6], "center": 7, "certain": 7, "chain": [5, 6], "challeng": [3, 5, 6], "chang": [1, 3, 4, 5], "chao": 6, "chapter": 5, "charact": [3, 6, 7], "characterist": 1, "chart": 5, "chase": 6, "check": [0, 3, 4, 5, 6], "checkbox": 1, "checkpoint": [0, 4, 5, 6, 7], "checkpoint_best": 4, "checkpoint_dir": 0, "checkpoint_fin": [4, 6, 7], "checkpoint_initial_run": 5, "checkpoint_path": 0, "checkpoint_step_10": 4, "checkpoint_step_20": 4, "cherish": [3, 5, 6], "chines": [5, 6], "choic": 3, "choos": 6, "choru": 6, "chosen": 5, "chunk": [3, 5, 6], "cjk": 7, "cl": [3, 5, 6], "claer": [3, 5, 6], "clariti": 5, "class": [0, 1, 2, 3, 4, 5, 6], "clean": 5, "clear": [0, 3, 4, 5, 6], "clear_gpu_memori": 0, "clear_memori": [3, 4, 5, 6], "clock": 3, "close": 2, "closer": 6, "cloud": [5, 6], "co": 2, "code": 4, "coeffici": 2, "coin": 5, "cold": 5, "collect": [3, 4, 5, 6], "colon": [3, 5, 6], "color": [1, 2, 3, 5, 6, 7], "column": 5, "column_stack": 1, "combin": [5, 6], "come": [3, 6], "comma": [1, 3, 5, 6], "common": [3, 5, 6], "compar": [1, 3, 4, 5], "comparison": [0, 1, 3], "compat": 3, "complet": [0, 2, 3, 4, 5, 6], "complex": 6, "compon": 0, "compound": [3, 5, 6], "comprehens": [0, 3], "comput": [0, 2, 3, 5, 6], "computation": [3, 5, 6], "concaten": [3, 5, 6], "concept": 3, "conclus": 0, "conda": 0, "conduct": 0, "config": [2, 3, 4, 5, 6], "configur": [2, 3, 5, 6], "confirm": 4, "connect": 0, "conquer": 3, "conserv": [3, 5, 6], "consid": [3, 5, 6], "consist": [1, 2, 6], "conson": 5, "constant": 6, "constraint": [0, 3, 5, 6], "consum": [3, 5, 6], "consumpt": 0, "contain": [0, 3, 5, 6], "content": [5, 6], "context": [0, 3, 4, 5, 6], "context_length": [0, 3, 4, 5, 6], "continu": [5, 6], "continuous_upd": 1, "control": [3, 5, 6], "convei": 3, "convert": [0, 1, 2, 3, 5, 6], "cool": 5, "copi": [5, 6], "core": [0, 3, 4, 7], "correct": 3, "cosin": [0, 2], "cost": [0, 3, 5, 6], "could": [3, 5, 6], "count": [0, 2, 3, 5, 6, 7], "count_trainable_paramet": 0, "courag": [3, 6], "cours": [0, 3, 4, 7], "coursework": [0, 1, 2, 4, 7], "cpu": [3, 4, 5, 6, 7], "craft": [3, 5, 6], "crash": 6, "creat": [0, 1, 2, 3, 5, 6], "crimson": 7, "crisp": 5, "criteria": [3, 5, 6], "cross": [3, 5, 6], "cross_entropi": [3, 5, 6], "crucial": [2, 3, 5, 6], "cuda": [3, 4, 5, 6], "cultivar": 6, "current": 4, "current_exp_flop": [3, 5, 6], "curv": 1, "custom": 4, "cut": 3, "cyclic": 1, "d": [3, 5, 6], "d62728": [3, 5, 6], "dai": [3, 6], "danc": [3, 5, 6], "dark": [3, 6], "darkest": 6, "data": [1, 4, 7], "data_fold": [1, 3, 4, 5, 6], "data_mast": [3, 4, 5, 6], "dataclass": 2, "datafram": 2, "dataload": [0, 3, 4, 5, 6], "datamast": [0, 3, 4, 5, 6], "dataset": [0, 3, 4, 5, 6], "dawn": [5, 6], "dear": 6, "decim": [1, 5], "decis": [3, 5, 6], "decod": [0, 1, 2, 3, 5, 6, 7], "decode_to_str": [0, 3, 5, 6], "decreas": [3, 5, 6], "dedic": [3, 5, 6], "deep": 3, "deepest": 6, "def": [1, 2, 3, 4, 5, 6], "default": [0, 4], "defin": [0, 1, 4, 6], "degrad": [3, 5, 6], "demonstr": [1, 2, 3, 4, 5, 6], "denomin": 5, "depend": [3, 5, 6], "depth": [3, 5, 6], "deriv": 6, "desc": [3, 5, 6], "descal": 0, "describ": 5, "descript": [0, 1, 3, 5, 6], "design": [0, 1, 3, 5, 6], "desir": 6, "destini": 6, "detach": 7, "detail": [0, 2, 3, 5], "detoken": 0, "develop": [3, 5, 6], "deviat": 1, "devic": [0, 3, 4, 5, 6], "df": 2, "df_infer": 2, "dict": [0, 7], "dictionari": 0, "did": 5, "diff": 1, "differ": [0, 1, 3, 5, 6], "digit": [3, 5], "dim": [3, 5, 6], "dimens": [2, 3], "dimension": 2, "direct": [1, 5, 6], "directli": [2, 3, 5, 6], "directori": 2, "dirnam": [1, 2, 3, 4, 5, 6], "discoveri": 6, "displai": [0, 1, 2, 3, 5, 6], "distant": 5, "distribut": [1, 7], "div": [2, 5], "diverg": [3, 5, 6], "divers": 3, "divid": [2, 5], "divis": [0, 2], "divisor": 5, "do": [3, 4, 5], "doc": [0, 4], "docker": 0, "document": [0, 4, 7], "doe": 3, "don": [0, 1, 2], "down": [2, 3, 5, 6], "dpi": [5, 6], "dream": [3, 5, 6], "dreamland": 6, "dreams\u7f16\u7ec7\u7740\u6211\u4eec\u7684\u672a\u6765": 5, "drift": 5, "drop": 6, "dropdown": 1, "drumbeat": 6, "dtype": [3, 5, 6], "due": [3, 4, 5, 6], "dump": [5, 6], "dure": [2, 3, 4, 5, 6], "dwell": 3, "dynam": [0, 3, 5, 6], "e": [1, 3, 5, 6], "each": [0, 1, 2, 3, 5, 6], "earthli": 6, "easier": 2, "eat": 3, "ec": 1, "echo": [5, 6], "ecolog": 1, "edg": 3, "edgecolor": 1, "ee": 5, "effect": [0, 1, 2, 3], "effici": [0, 2, 3, 4, 5, 6], "eh": 5, "either": [3, 5, 6], "element": [2, 5], "elif": 1, "els": [2, 3, 4, 5, 6], "embark": 6, "embed": 2, "embrac": [3, 5, 6], "emerg": 3, "empti": [4, 5, 6], "empty_cach": [3, 4, 5, 6], "enabl": [1, 2, 3, 4, 6], "encapsul": 1, "enchant": 5, "encod": [0, 1], "encount": [3, 4, 6], "encourag": [3, 6], "end": [1, 3, 5, 6], "endless": [3, 6], "engag": 3, "enhanc": 1, "enjoi": 5, "ensur": [1, 3, 5, 6], "entir": [3, 5, 6], "entropi": [3, 5, 6], "entwin": 6, "enumer": [1, 3, 5, 6, 7], "env": 0, "envelop": 0, "environ": 0, "eo": 3, "eos_token_id": 3, "epoch": 4, "epsilon": 2, "equal": 6, "equat": [0, 6], "error": [0, 1, 3, 4, 5, 6], "essenc": [3, 5, 6], "essenti": 1, "establish": [3, 5, 6], "estim": 2, "et": 3, "etern": 6, "eval": [0, 3, 5, 6], "eval_interv": [0, 4, 5, 6], "evalu": [0, 1, 2], "evaluation_loop": 0, "even": [1, 3, 5, 6], "everi": [0, 3, 5, 6], "evok": [3, 5, 6], "evolv": [3, 5, 6], "exact": 6, "examin": [1, 2, 3, 5, 6], "exampl": [2, 3, 4, 5, 6], "except": [3, 4, 5, 6], "execut": 4, "exist": [0, 5, 6], "exp": 2, "expand": 3, "expans": [5, 6], "expect": [3, 5, 6], "expens": [3, 5, 6], "experi": [2, 3, 4, 5, 6], "experienc": 6, "experiment": [0, 3, 5, 6], "experiment_fin": 0, "experiment_fract": [0, 3, 4, 5, 6], "experiment_initi": 0, "explan": 2, "explicit": 0, "explor": [0, 3, 5, 6], "exponenti": [0, 2], "express": [5, 6], "extract": [1, 3, 5, 6], "extran": 3, "ey": 6, "f": [0, 1, 2, 3, 4, 5, 6, 7], "face": [0, 3], "facecolor": 7, "fact": [3, 5, 6], "factor": [1, 2, 3, 5, 6], "fade": [5, 6], "fail": 4, "failur": [3, 4], "fall": [5, 6], "fals": [0, 1, 2, 3, 4, 5, 6, 7], "famili": 5, "fanci": 1, "far": 5, "fast": 5, "faster": [0, 3, 5, 6], "fc": 1, "fear": [3, 6], "feasibl": 0, "feed": 0, "feedback": 3, "feel": 3, "few": [3, 4, 5, 6], "ff7f0e": [3, 5, 6], "ffn": 2, "ffn_breakdown": 2, "ffn_dim": 2, "ffn_flop": 2, "fibonacci": 5, "fidel": 1, "field": 5, "fifth": 6, "fig": [2, 3, 5, 6, 7], "figsiz": [1, 2, 3, 5, 6, 7], "figur": [1, 2, 3, 5, 6, 7], "file": [0, 1, 3, 4, 5, 6], "fill": [1, 6], "fill_between": 1, "filter": 5, "final": [0, 1, 3, 4, 5, 6, 7], "find": [3, 5, 6], "fine": [0, 2, 3, 5, 6], "first": [1, 3, 5, 6], "fit": 2, "fix": [1, 2, 5, 6], "flame": 3, "flash": 6, "flatten": 1, "fleet": 6, "flit": 5, "float": [0, 2, 3, 5, 6], "float32": [3, 5, 6], "floor": [0, 3], "flops_calcul": 2, "flops_count": [3, 5, 6], "flops_df": [3, 5, 6], "flops_logg": [3, 5, 6], "flops_per_it": 2, "flops_us": [3, 5, 6], "flow": [3, 5, 6], "flower": 5, "folder": [1, 3, 4, 5, 6], "follow": [0, 1, 2, 3, 4, 6], "font": 7, "fontsiz": [1, 3, 5, 6, 7], "fontweight": [1, 3, 5, 6], "forc": 4, "forecast": 1, "forest": 5, "forev": [3, 5, 6], "forget": 0, "form": [3, 5, 6], "format": [0, 2, 3, 7], "formatted_pred": 1, "formatted_prei": 1, "formatted_str": 1, "former": 0, "formula": [2, 3, 6], "forward": [0, 3, 4, 5, 6], "found": 5, "foundat": 6, "fourth": 6, "frac": [3, 5, 6], "fraction": [3, 4, 5, 6], "frame": 1, "framealpha": [3, 5, 6], "frameon": [1, 3, 5, 6], "free": [0, 6], "freez": [3, 4, 5, 6], "frequenc": 1, "fresh": 5, "from": [0, 1, 2, 3, 4, 5, 6, 7], "from_pretrain": [1, 3, 4, 5, 6, 7], "frozen": 0, "fruit": [5, 6], "full": [0, 1, 3, 4, 5, 6], "full_sequ": [3, 5, 6], "full_sequence_valu": [3, 5, 6], "fullest": 6, "fulli": [0, 7], "function": [0, 2, 3, 4, 5, 6], "further": [3, 5, 6], "futur": [3, 5, 6], "g": [1, 3, 5, 6], "gain": 6, "gate": 2, "gather": 5, "gaug": 3, "gc": [3, 4, 5, 6], "gee": 5, "gener": [0, 1, 2, 3, 4, 5, 6, 7], "generated_id": [3, 5, 6], "generated_part": 3, "generated_text": 3, "genet": 6, "gentl": 5, "gentli": 5, "get": [1, 3, 5, 6, 7], "get_attention_flop": [0, 2], "get_data": [0, 3, 4, 5, 6], "get_ffn_flop": [0, 2], "get_flop": [0, 2, 3, 4, 5, 6], "get_fram": 1, "get_lm_head": [0, 2], "get_lora_flop": [0, 2], "get_loss_flop": [0, 2], "get_residual_flop": [0, 2], "get_rmsnorm_flop": [0, 2], "give": [2, 3, 5, 6], "given": [2, 3, 6], "glassi": 6, "glimmer": 6, "global": 4, "glow": [5, 6], "glyph": 7, "goal": 6, "gold": 5, "golden": 5, "gon": 5, "gone": 6, "good": 3, "got": 4, "gotten": 2, "gpu": [0, 3, 4, 5, 6], "grace": 6, "gradient": [0, 2], "grand": [5, 6], "great": [5, 6], "greatest": 5, "green": [3, 5, 6], "grid": [0, 1, 2, 3, 5, 6, 7], "grid_checkbox": 1, "gridspec_kw": 7, "ground": [3, 5, 6], "grow": [5, 6], "growth": [3, 5, 6], "gruver": 3, "gt": 7, "guid": [3, 5, 6], "guidanc": 6, "gun": 5, "h3": 2, "h5": [1, 3, 4, 5, 6], "h5py": [1, 3, 4, 5, 6], "ha": [2, 3, 4, 5, 6, 7], "had": 3, "hall": 3, "handl": [0, 1, 3, 5, 6], "happi": 3, "hard": 3, "harmoni": 5, "have": [2, 3, 4, 5, 6, 7], "he": [4, 5, 6], "head": [0, 3, 4, 5, 6, 7], "head_dim": 2, "head_length": 1, "head_width": 1, "hear": [3, 5], "heart": [3, 5, 6], "height_ratio": 7, "help": [1, 2, 3, 5, 6], "helper": 0, "here": [0, 3, 4, 5, 6, 7], "hidden": [0, 2], "hidden_dim": 2, "high": [1, 3, 5, 6], "highest": 7, "highlight": [1, 2, 3, 5, 6, 7], "highlight_max_iter": 2, "hist": 1, "histogram": 7, "histor": [3, 5, 6], "histplot": 7, "hline": 5, "hold": [3, 5, 6], "home": 6, "hook": 0, "hope": [3, 5, 6], "horizon": [3, 5, 6], "horizontalalign": 7, "hour": 6, "how": [1, 2, 3, 4, 5, 6, 7], "howev": [3, 5, 6], "html": [2, 4], "http": 4, "hue": 5, "hug": 0, "huh": 5, "hum": 5, "human": [3, 6], "hundredth": 5, "hyperparamet": [0, 2, 3, 5, 6], "i": [0, 1, 2, 3, 4, 5, 6, 7], "id": [0, 1], "idea": [3, 5, 6], "ident": 6, "identifi": 3, "ideograph": 7, "idx": 7, "ignor": [0, 4], "ignore_kei": 0, "illumin": 6, "illustr": 4, "imag": 5, "imageri": [3, 5, 6], "imagin": 5, "impact": [3, 5, 6], "implement": [0, 2, 3, 4, 5, 6], "implicit": 3, "import": [1, 2, 3, 4, 5, 6, 7], "importlib": 4, "improv": [0, 3, 5, 6], "in_dim": [4, 5, 6], "in_featur": [4, 5, 6], "includ": [0, 2, 6], "incorpor": [4, 6], "increas": [3, 4, 5, 6], "indefinit": 5, "indent": 3, "index": [0, 3, 5, 6, 7], "indic": [3, 5, 6, 7], "individu": 0, "infer": [0, 2, 3, 4, 5, 6], "infer_flops_by_batch": 2, "infer_flops_by_seq": 2, "inference_flop": 2, "influenc": 1, "inform": [1, 2, 3, 4, 5, 6], "inher": [3, 5, 6], "init": [4, 5, 6], "initi": [0, 1, 3, 4, 5, 6], "initialis": [4, 5, 6], "inner": 6, "input": [0, 2, 3], "input_id": [1, 3, 5, 6], "input_ids_valu": [3, 5, 6], "insight": [2, 3, 5, 6], "inspir": [5, 6], "instanc": [0, 2, 3, 5, 6], "instead": [0, 2], "instruct": [0, 1, 3, 4, 5, 6, 7], "int": [0, 1, 2, 4, 5, 6], "interact": [0, 2], "interactive_plot": 1, "interconnected": 6, "interest": [3, 5, 6], "interleav": 1, "interlud": 6, "intermedi": 2, "interpret": 2, "intertwin": 6, "intrangeslid": 1, "introduc": [3, 5, 6], "introduct": 0, "intslid": 1, "inv": 2, "invalid": 0, "invers": [0, 2], "invest": 3, "invit": 5, "involv": [0, 4, 5, 6], "io": 2, "ipc_collect": [3, 4, 5, 6], "ipykernel": 0, "ipykernel_29008": 7, "ipynb": [5, 6], "ipython": [1, 2, 7], "ipywidget": 1, "is_avail": [3, 4, 5, 6], "is_max": 2, "is_merg": [4, 5, 6], "is_world_process_zero": 0, "isinst": [4, 5, 6], "issu": 3, "item": [2, 3, 5, 6], "iter": [2, 3, 5, 6], "its": [3, 5, 6], "itself": 0, "j": [3, 5, 6], "johnson": 5, "joi": [3, 5], "join": [1, 2, 3, 4, 5, 6], "journei": [3, 5, 6], "jump": [3, 5, 6], "jupyt": [1, 2, 3, 4, 5, 6, 7], "just": [3, 5, 6], "k": [2, 5], "kaiming_normal_": [4, 5, 6], "kaleidoscop": 5, "kde": 7, "keep": [1, 3], "kei": [0, 1, 3, 4, 5, 6], "kind": 3, "know": [3, 6], "knowledg": [3, 4], "kw": 7, "kwarg": [], "label": [1, 2, 3, 5, 6, 7], "land": 6, "languag": [0, 1, 3, 5, 6], "larg": [0, 3], "larger": [3, 5, 6], "largest": 5, "last": [3, 5], "latter": 0, "laugh": 3, "laughter": [5, 6], "layer": [0, 2, 4, 5, 6], "layernorm": 2, "lead": [3, 4, 5, 6], "learn": [0, 1, 3, 4, 5, 6], "learnabl": 2, "learning_r": [0, 5, 6], "learnt": [3, 5, 6], "least": [3, 5, 6], "leav": [3, 5, 6], "left": [3, 5, 6], "leftmost": 5, "legaci": 5, "legend": [1, 2, 3, 5, 6, 7], "len": [1, 3, 5, 6, 7], "length": [0, 2, 3, 4, 5, 6], "lent": [4, 7], "less": 4, "let": [1, 2, 3, 4, 5, 6], "letter": 6, "leverag": 1, "li": [3, 5, 6], "lib": [4, 7], "life": [3, 5, 6], "light": [1, 3, 5, 6], "lightgrai": 1, "lightyellow": 7, "like": [3, 4, 5, 6], "limit": [3, 5, 6], "line": [5, 6], "linear": [0, 3, 4, 5, 6], "linestyl": [3, 5, 6, 7], "linewidth": [1, 3, 5, 6, 7], "linger": [5, 6], "link": 5, "linspac": 1, "list": 0, "live": [3, 5, 6], "ll": [1, 2, 3, 5, 6], "llmtime": [0, 3, 5, 6], "llmtime_str": 1, "lm": [0, 2, 3, 4, 5, 6], "lm_head": [3, 4, 5, 6, 7], "lm_head_breakdown": 2, "lm_head_flop": 2, "load": [0, 1, 3, 4, 5, 6, 7], "load_checkpoint": [0, 5, 6], "load_qwen": [0, 3, 4, 5, 6], "load_state_dict": [5, 6], "loader": [3, 5, 6], "loc": [1, 2, 3, 5, 6], "local": [4, 7], "log": [0, 2, 4], "log10": [2, 3, 5, 6], "log_fil": [3, 5, 6], "log_flop": [0, 3, 5, 6], "log_flops_to_wandb": 0, "log_gradient_stat": 0, "log_interv": 0, "log_nam": [3, 5, 6], "logarithm": [0, 2], "logged_metr": [3, 5, 6], "login": 4, "logit": [2, 3, 4, 5, 6], "long": [3, 5, 6], "look": [2, 3, 5], "loop": [0, 3], "lora": [3, 5, 6], "lora_breakdown": 2, "lora_flop": 2, "lora_out": [4, 5, 6], "lora_rank": [0, 2, 4, 5, 6], "lora_weight": 0, "loralinear": [0, 4, 5, 6], "loratrain": [0, 4], "lose": [3, 5, 6], "loss": [0, 1, 3, 4, 5, 6], "loss_breakdown": 2, "loss_flop": 2, "lost": 6, "lot": 3, "lotka": [0, 3, 5, 6], "lotka_volterra_data": [1, 3, 4, 5, 6], "lotkavolterradataset": [0, 3, 4, 5, 6], "love": [3, 5, 6], "low": [0, 1, 2, 5, 6], "lr": 0, "lr1e": 4, "lt": [3, 4, 5, 6, 7], "lyric": [3, 5, 6], "l\u011bi": 6, "m": [0, 3], "m2": [0, 4, 7], "mae": [0, 1, 3, 4, 5, 6], "mae_": [3, 5, 6], "mae_by_context": [3, 5, 6], "mae_per_tim": [3, 5, 6], "mae_valu": [3, 5, 6], "magic": 3, "magnitud": 5, "mah": 5, "mai": [3, 4, 5, 6], "main": [0, 7], "maintain": 1, "make": [2, 3, 5, 6], "manag": [0, 3, 4, 5, 6], "mani": [2, 3, 5, 6], "manual_se": [3, 4, 5, 6], "map": [1, 2], "map_loc": [5, 6, 7], "marker": [2, 3, 5, 6], "markers": [3, 5, 6], "matplotlib": [1, 2, 3, 4, 5, 6, 7], "matric": [0, 5, 6], "matrix": 2, "matter": 3, "max": [1, 2, 3, 4, 5, 6, 7], "max_budget": [5, 6], "max_error": 1, "max_flops_budget_perc": 0, "max_iter": 2, "max_length": [3, 5, 6], "max_magnitud": [0, 1], "max_new_token": [3, 5, 6], "max_step": [0, 4, 5, 6], "maximum": [1, 3, 5, 6], "maze": 5, "me": [3, 4, 6], "mean": [0, 1, 2, 3, 4, 5, 6, 7], "meaning": 5, "meaningfulli": [3, 5, 6], "measur": [3, 5, 6], "mechan": [0, 2], "median": 7, "meet": [0, 5], "melodi": [5, 6], "member": 5, "memor": 3, "memori": [0, 3, 4, 5, 6], "merg": [0, 2, 4, 5, 6], "merge_lora_weight": 0, "merged_weight": [4, 5, 6], "messag": [3, 4, 5, 6], "metaphor": [3, 5, 6], "method": [0, 4, 5], "metric": [0, 1, 3, 4, 5, 6], "metric_key_prefix": 0, "mha": 2, "midst": 6, "might": [1, 3, 5, 6], "min": [1, 7], "mind": [3, 5, 6], "minim": 1, "mirror": 6, "miss": 7, "model": [0, 1, 3, 5, 6, 7], "model_input": [3, 5, 6], "model_nam": [0, 1, 3, 4, 5, 6, 7], "model_state_dict": [5, 6], "modif": [2, 3, 4, 5, 6], "modul": [4, 5, 6], "moment": [3, 5, 6], "monoton": 4, "moon": [5, 6], "more": [2, 3, 4, 5, 6], "morn": 3, "most": [3, 5, 6], "mostli": 1, "motion": 5, "mountain": 6, "move": [3, 5, 6], "mphil": [4, 7], "mpl": 1, "mse": [0, 3, 4, 5, 6], "mse_": [3, 5, 6], "mse_by_context": [3, 5, 6], "mse_per_tim": [3, 5, 6], "mse_valu": [3, 5, 6], "much": [1, 3, 5, 6], "mul": 2, "multi": 0, "multiarrai": 4, "multipl": [0, 2, 3, 5, 6], "multipli": [2, 6], "multivari": 1, "mundan": 3, "must": [3, 4, 5, 6], "my": [3, 5, 6], "mysteri": 5, "n": [0, 1, 3, 4, 5, 6, 7], "n0": 5, "n15": 3, "nadd": 3, "name": [0, 3, 5, 6], "named_paramet": 4, "nan": [3, 5, 6], "nand": 3, "nanonym": 3, "nanswer": 5, "narr": [5, 6], "nask": 5, "natur": [3, 5, 6], "naturalist": 5, "navi": 7, "navig": [5, 6], "nbecaus": 5, "nbest": [3, 5], "nbsp": 2, "nbut": 3, "ncopi": [3, 5], "ndarrai": 0, "neduardo": 3, "nee": 5, "need": [0, 1, 2, 3, 4, 6], "neg": [2, 3, 7], "negat": [0, 2], "neh": 5, "nerror": 1, "network": 0, "never": [3, 5], "new": [3, 4, 5, 6], "newli": [3, 5, 6], "nexplan": 5, "next": [1, 2, 3, 5, 6], "next_token": [3, 5, 6], "next_token_logit": [3, 5, 6], "nfirst": 1, "nflower": 5, "nfood": 3, "nfor": 3, "ngener": 3, "ngeographi": 5, "nhave": 3, "nhead": 3, "nhelp": [3, 5], "nhow": [3, 5], "nice": [3, 4, 5, 6, 7], "nif": 3, "night": [3, 5, 6], "nightmar": 6, "ninfer": 2, "ninterleav": 1, "nit": [3, 5], "njare": 5, "nkathryn": 5, "nlvl": 3, "nmath": [3, 5], "nmore": 3, "nn": [3, 4, 5, 6, 7], "nnot": 5, "nnumber": 3, "no_grad": [3, 5, 6], "noisi": [3, 5, 6], "none": [0, 3, 4, 5, 6], "nonli": 3, "nonlinear": [4, 5, 6], "noo": 5, "nor": 3, "norigin": 1, "normal": [0, 2], "note": [0, 2, 3], "notebook": [1, 2, 3, 4, 5, 6, 7], "notic": [3, 5, 6, 7], "now": [1, 2, 3, 4, 5, 6], "np": [0, 1, 2, 3, 4, 5, 6, 7], "npeopl": [3, 5], "npredat": 1, "nrelat": 5, "nsamantha": 5, "nsee": [3, 5], "nsever": 5, "nso": 3, "nstrawberri": 5, "nsubmit": 3, "nthe": 5, "nthere": [3, 5], "ntherefor": 3, "nthi": [3, 5], "ntop": 5, "ntotal": 2, "ntrevor": 5, "num_head": 2, "num_lay": 2, "num_system": 1, "num_top": 7, "number": [0, 2, 3, 4, 5, 6], "numer": [0, 1, 3, 5, 6], "numericalprocessor": [0, 3, 4, 5, 6], "numpi": [1, 2, 3, 4, 5, 6, 7], "nwere": 3, "nwhat": [3, 5], "nwhen": 5, "nwiki": [3, 5], "o": [1, 2, 3, 4, 5, 6], "object": 0, "observ": [3, 5, 6], "occur": 3, "ocean": 6, "off": [2, 3], "offer": 6, "offset": 7, "often": 3, "oh": [3, 5], "old": 5, "one": [0, 3, 5, 6], "onedr": [4, 7], "onli": [0, 2, 3, 4, 5, 6, 7], "onto": [3, 6], "open": [5, 6], "oper": [0, 6], "operationflop": [0, 2], "opportun": 4, "optim": [0, 2, 3, 5, 6], "option": [0, 1, 3, 4], "order": 4, "org": 4, "organ": 0, "orig": 1, "origin": [0, 1, 2, 3, 4, 5, 6, 7], "original_length": [3, 5, 6], "original_linear": [0, 4, 5, 6], "other": [1, 3, 4, 5, 6], "our": [1, 2, 3, 4, 5, 6], "ourselv": [5, 6], "out": [3, 4, 5, 6], "out_dim": [4, 5, 6], "out_featur": [4, 5, 6], "outcom": 3, "outlier": 1, "output": [0, 1, 2, 3, 5, 6], "output_id": [3, 5, 6], "outsid": 5, "over": [0, 1, 3, 5, 6], "overal": [1, 3, 5, 6], "overcom": 3, "overli": 1, "overridden": 0, "overview": 0, "own": [3, 5, 6], "p": [0, 1, 3, 4, 5], "pack": 3, "packag": 7, "pad": [0, 1, 5, 6, 7], "pad_token_id": 3, "page": [0, 1, 2, 3, 4, 5, 6, 7], "pain": [5, 6], "paint": 5, "pair": [3, 5, 6], "panda": [2, 3, 4, 5, 6], "paper": 1, "param": [3, 4, 5, 6], "paramet": [0, 3, 4, 5, 6], "pardir": [3, 4, 5, 6], "pars": 0, "part": [3, 5, 6], "particular": 3, "pass": [0, 2, 3], "past": [5, 6], "path": [0, 1, 2, 3, 4, 5, 6], "patienc": 3, "pattern": [1, 3, 5, 6], "pd": [2, 3, 4, 5, 6], "peac": [3, 5, 6], "per": [2, 3, 5, 6], "per_step_c": [3, 5, 6], "percent": [3, 5, 6], "percentil": 1, "perfect": 5, "perform": [0, 4], "perhap": 5, "period": [3, 5, 6], "person": [3, 5], "perstep": [3, 5, 6], "phase": 1, "phase_spac": 1, "pickl": [5, 6], "pink": 1, "pip": 0, "pipelin": [], "pizza": 3, "pkl": [5, 6], "place": [1, 5], "plai": 6, "plan": [0, 3, 5, 6], "plant": [3, 6], "pleas": [3, 4], "plight": 3, "plot": [1, 2, 3, 5, 6, 7], "plot_trajectori": 1, "plot_typ": 1, "plot_type_dropdown": 1, "plt": [1, 2, 3, 4, 5, 6, 7], "poem": [3, 5, 6], "poetic": 5, "poetri": [3, 5], "point": [1, 2, 3, 5, 6, 7], "poorest": 3, "popul": [0, 1, 3, 5, 6], "popular": 5, "posit": [2, 3, 7], "positive_i": 7, "positive_mask": 7, "positive_x": 7, "possibl": 6, "postprocess": [0, 1, 3, 5, 6], "potenti": [0, 5, 6], "power": [3, 5, 6], "practic": 3, "pre": [0, 3], "precis": [0, 1], "pred_val": [3, 5, 6], "predat": [0, 3, 5, 6], "predator_color": 1, "predator_data": 1, "predator_rgba": 1, "predator_sampl": 1, "predict": [1, 3, 5, 6], "predicted_valu": [3, 5, 6], "prediction_loss_onli": 0, "prei": [0, 3, 5, 6], "prepar": [0, 4], "preprocess": [0, 3, 5, 6], "preprocessed_str": 1, "preprocessor": [1, 3, 4, 5, 6], "present": 2, "preserv": [1, 4], "pretrainedtoken": 0, "previou": 5, "previous": 3, "prey_color": 1, "prey_data": 1, "prey_rgba": 1, "prey_sampl": 1, "principl": 3, "print": [0, 1, 2, 3, 4, 5, 6, 7], "print_figur": 7, "problem": 3, "proc": 1, "proce": 4, "procedur": [3, 5, 6], "process": [0, 1, 2, 3, 4, 5, 6], "processed_data": 1, "processor": [0, 1, 3, 4, 5, 6], "produc": [3, 5, 6], "progress": [1, 3, 5, 6], "project": [2, 4, 5, 6], "project_nam": 0, "promis": 3, "prompt": [3, 5, 6], "prompt_list": [3, 5, 6], "pronounc": 5, "pronunci": 5, "prop": 7, "propag": [3, 5, 6], "proper": 3, "properli": 3, "propos": [3, 5, 6], "provid": [0, 1, 2, 3, 5, 6], "pt": [1, 3, 5, 6], "pth": [4, 5, 6, 7], "punctuat": [1, 3, 5, 6], "pure": 5, "purpl": 1, "purpos": [3, 4, 5], "pursu": 6, "push": 3, "py": [1, 2, 7], "pylabtool": 7, "pyplot": [1, 2, 3, 4, 5, 6, 7], "python": 0, "pytorch": [3, 4, 5, 6], "q": [1, 2, 5], "q_proj": [4, 5, 6], "qi\u01cen": 6, "qi\u01cenl\u011bi": 6, "qi\u01cent\u00e9ir": 6, "qi\u01cen\u00e9r": 6, "qk": 2, "qkv": 2, "quad": 5, "qualiti": [3, 5, 6], "queri": [2, 5, 6], "question": [5, 6], "quick_ev": 0, "quiet": [3, 5, 6], "quit": [3, 5, 6], "qwen": [0, 1, 2, 3, 4, 5, 6, 7], "qwen2": [3, 4, 5, 6, 7], "qwen_finetune_lora_data": [5, 6], "qwen_finetune_lora_result": [5, 6], "qwenflopscalcul": [0, 2, 3, 4, 5, 6], "r": [0, 1, 2, 3, 4, 5, 6], "r4": 4, "rah": 5, "rais": 0, "random": [3, 4, 5, 6], "rang": [1, 3, 5, 6, 7], "rank": [0, 2, 3, 5, 6, 7], "rate": [0, 3, 4, 5, 6], "ratio": 2, "raw": [0, 1], "rb": [5, 6], "re": [3, 4, 5, 6], "reach": [0, 3, 5, 6], "read": [5, 6], "read_csv": [3, 5, 6], "readabl": [3, 5, 6], "reader": [3, 5, 6], "readi": 0, "readili": 3, "realiti": 6, "realli": 3, "realm": [3, 5, 6], "reason": [1, 3, 5, 6], "rec": 1, "recip": 0, "reciproc": 6, "recommend": 4, "recov": 1, "recovered_data": 1, "rect": [3, 5, 6], "red": [1, 2, 3, 5, 6], "reduc": [3, 5, 6], "ree": 5, "reee": 5, "reen": 5, "refer": [4, 5], "reflect": [5, 6], "regist": 0, "rel": [3, 5, 6], "relat": 5, "releas": 6, "reli": [3, 5, 6], "reload": 4, "relogin": 4, "relu": [0, 2], "remain": [3, 5, 6], "rememb": [3, 5, 6], "repeat": [3, 5, 6], "repetit": 3, "replac": 7, "report": 2, "repres": [0, 3, 6], "represent": 0, "request": 3, "requir": [0, 1, 2, 3, 5, 6], "requires_grad": [3, 4, 5, 6], "reset_peak_memory_stat": [3, 4, 5, 6], "reshap": 3, "residu": 0, "residual_breakdown": 2, "residual_flop": 2, "resourc": [0, 3, 5, 6], "respect": 6, "respons": [3, 5, 6], "rest": 7, "restor": 0, "result": [1, 4], "result_ids_valu": [3, 5, 6], "result_tim": [3, 5, 6], "retain": 3, "return": [0, 2, 3, 4, 5, 6], "return_tensor": [1, 3, 5, 6], "reveal": [3, 5, 6], "revis": 3, "rewrit": 5, "rgba": 1, "rhythm": 5, "rhythmic": [3, 5, 6], "right": [3, 5, 6, 7], "ring": 6, "rise": [5, 6], "risk": 3, "river": [3, 5, 6], "rm": 0, "rmse": 1, "rmsnorm": 0, "rmsnorm_breakdown": 2, "rmsnorm_flop": 2, "road": 6, "roam": 6, "robust": 3, "role": [5, 6], "root": [0, 1, 2], "rosa": 5, "rotari": 2, "rotat": 7, "round": [0, 7], "row": [3, 5, 6], "ruffin": 5, "run": [0, 3, 4, 5, 6], "run_nam": 0, "rustl": 5, "safe_glob": 4, "said": 5, "sake": 5, "same": [1, 2, 3, 5, 6], "sampl": [0, 4], "sample_idx": 1, "sample_pred": 1, "sample_prei": 1, "saniti": [3, 4, 5, 6], "save": [0, 4, 5, 6], "save_checkpoint": 0, "save_interv": [0, 4], "scalar": 4, "scale": [0, 3, 5, 6], "scaled_pred": 1, "scaled_prei": 1, "scaler": [3, 5, 6], "scaling_factor": 1, "scatter": [1, 7], "scene": 5, "scheme": [0, 3, 5, 6], "score": 2, "script": [0, 5, 6], "sdk": 4, "sdpa": [3, 4, 6], "sea": [5, 6], "seaborn": [1, 7], "search": [0, 3, 5, 6], "sec": 4, "second": [5, 6], "secret": [3, 5], "see": [2, 3, 4, 5, 6, 7], "seed": [3, 4, 5, 6], "seek": 6, "seem": 6, "seen": 6, "select": [1, 2], "selected_tim": 1, "self": [4, 5, 6], "self_attn": [4, 5, 6], "semi": [3, 5, 6], "semi_colon_count": [3, 5, 6], "semi_colon_max": [3, 5, 6], "semicolon": [0, 1, 3, 5, 6], "sens": [2, 5], "sensit": [3, 5, 6], "separ": 1, "seq": 2, "seq_len": [0, 2, 3, 5, 6], "seq_length": 2, "sequenc": [0, 2, 3, 5, 6], "sequence_length": [0, 3], "sequenti": [3, 5, 6], "seren": 5, "seri": 1, "serial": 4, "serv": [0, 3, 4, 6], "set": [0, 1, 3, 4, 5, 6, 7], "set_alpha": 1, "set_edgecolor": 1, "set_facecolor": 1, "set_styl": 7, "set_titl": [2, 3, 5, 6, 7], "set_xlabel": [2, 3, 5, 6, 7], "set_xtick": [3, 5, 6], "set_ylabel": [2, 3, 5, 6, 7], "setup_lora_model": 0, "sever": [0, 3, 5, 6], "shadow": [3, 5, 6], "shall": [3, 6], "shape": [0, 1, 3, 5, 6], "share": [3, 5], "shield": 6, "shift": 5, "shine": [3, 6], "shore": 6, "short": 0, "shot": 0, "should": [0, 3, 5, 6], "show": [1, 2, 3, 5, 6, 7], "show_grid": 1, "showcas": [1, 3, 4], "shy": 5, "side": [1, 3], "sigh": 6, "sight": 6, "sign": 3, "significantli": [3, 5, 6], "silent": [0, 6], "silu": 2, "silver": 5, "similar": [0, 3, 5, 6], "simpl": [2, 6], "simpli": [3, 5], "simplifi": [2, 5, 6], "simul": 0, "sin": 2, "sinc": [0, 2, 3, 5, 6], "sine": [0, 2], "singl": [0, 6], "site": 7, "situat": 3, "sixth": 6, "size": [0, 1, 2, 3, 5, 6, 7], "ski": 6, "skill": 3, "skip_special_token": [3, 5, 6], "sky": 5, "sl": 2, "sleep": 3, "slide": [3, 4, 6], "slight": 4, "slightli": 6, "small": [0, 2, 3, 4, 5, 6], "smaller": [3, 5, 6], "smallest": 6, "smile": [3, 5, 6], "smith": 5, "smooth": [3, 5, 6], "sn": 7, "so": [3, 4, 5, 6, 7], "soar": 3, "soft": 5, "softmax": 2, "solac": [3, 6], "solv": 3, "some": [1, 2, 3, 4, 5, 6], "someon": 5, "someth": [5, 6], "sometim": [3, 5, 6], "song": 5, "sooth": 5, "sorri": 3, "sorrow": [3, 6], "sort": 2, "sort_valu": 2, "soul": [3, 5, 6], "sound": [5, 6], "sourc": [0, 4], "space": [1, 2, 3], "spark": 3, "sparsiti": 7, "speaker": 3, "speci": 6, "special": 1, "specif": [0, 2, 3, 5, 6], "specifi": [2, 5, 6], "speed": 4, "spent": 6, "spirit": 6, "split": [1, 3, 5, 6], "spread": [3, 5], "spun": 6, "sqrt": [1, 2], "squar": [0, 1, 2, 3, 5, 6], "squeez": [1, 3, 5, 6], "src": [0, 1, 2, 3, 4, 5, 6], "stabil": [3, 5, 6], "stabl": 4, "stage": 0, "stai": [0, 3, 5, 6], "stand": [3, 5], "standard": 1, "stanza": 6, "star": [3, 5, 6], "start": [1, 3, 5, 6], "starter": 5, "startswith": 2, "stat": [2, 7], "state": [0, 2], "state_dict": [5, 6], "statist": [0, 1, 7], "stem": 5, "step": [0, 1, 3, 4, 5, 6], "steps19": 4, "steps9": 4, "still": [4, 5, 6], "stone": 3, "stop": 3, "stori": [3, 5, 6], "str": [0, 1, 5, 6], "strategi": [3, 5, 6], "straw": 6, "strawberri": [3, 5, 6], "strength": [3, 5, 6], "strict": [0, 5, 6], "strife": 6, "string": 0, "strip": 1, "strong": 6, "stronger": [3, 6], "structur": [1, 5, 6], "struggl": [3, 5, 6], "style": [1, 2, 3, 7], "styled_df": 2, "styler": 2, "sub": 2, "subclass": 0, "submiss": 3, "subplot": [1, 2, 3, 5, 6, 7], "subsequ": [3, 5], "subset": [2, 3, 5, 6], "substitut": 3, "subtract": [0, 2, 6], "succe": 4, "success": [3, 5], "successfulli": [5, 6], "suffix": 0, "suggest": 3, "suit": 0, "suitabl": [1, 3, 5, 6], "sum": [3, 5, 6, 7], "sun": 5, "sunlight": 5, "sunset": 6, "super": [4, 5, 6], "support": [3, 5, 6], "suptitl": [3, 5, 6], "sure": [5, 6], "sustain": 6, "swai": 3, "swallow": 6, "sweat": 6, "sweep": 0, "swiglu": 2, "swim": 6, "sy": [1, 2, 3, 4, 5, 6], "syllabl": 5, "symphoni": 5, "sync": 4, "system": [1, 3, 5, 6], "s\u0101o": 5, "t": [0, 1, 2, 3, 4, 5, 6], "tabl": 2, "take": [0, 3], "tale": [3, 5, 6], "tapestri": [3, 5, 6], "tar_val": [3, 5, 6], "target": [3, 4, 5, 6], "target_eval_pair": [0, 3, 4, 5, 6], "target_valu": [3, 5, 6], "task": [0, 3, 5, 6], "tast": 6, "tear": [5, 6], "techniqu": [0, 3, 5, 6], "tell": [3, 5, 6], "temp": 7, "temp_test_loader_act": [3, 5, 6], "tempor": [1, 3, 5, 6], "tensor": [0, 3, 5, 6, 7], "tenth": 5, "term": [0, 3, 5, 6], "termin": [3, 5, 6], "test": [0, 3, 4, 5, 6], "test_load": [0, 3, 4, 5, 6], "test_siz": [0, 3, 4, 5, 6], "testament": 6, "text": [0, 1, 3, 5, 6, 7], "textcoord": 7, "th": 6, "than": [3, 4, 5], "thank": 3, "thei": [3, 5, 6], "them": [0, 1, 3, 5, 6, 7], "themselv": 5, "theoret": 0, "therefor": [3, 5, 6], "thi": [0, 1, 2, 3, 4, 5, 6, 7], "thing": 3, "third": [3, 5, 6], "those": [3, 4], "though": [3, 6], "thought": 6, "thousandth": 5, "thread": [3, 5, 6], "three": 6, "thrive": 6, "through": [1, 3, 5, 6], "throughout": [2, 3], "thu": [2, 3], "ti": 5, "tick": 3, "tight": 0, "tight_layout": [1, 2, 3, 5, 6, 7], "time": [1, 2, 4], "time_point": [1, 3, 4, 5, 6], "time_rang": 1, "time_range_slid": 1, "time_seri": 1, "time_step": [3, 5, 6], "timestamp": [3, 5, 6], "timestep": [1, 3, 5, 6], "titl": [1, 2, 3, 5, 6], "togeth": [3, 5, 6], "token": [0, 4, 5, 6, 7], "token_id": 1, "token_text": 1, "tokenized_sampl": 1, "tokens_process": 2, "told": 3, "tolist": 1, "tone": 3, "tongu": 6, "too": [3, 5], "tool": [1, 3], "top": 7, "top_indic": 7, "top_token": 7, "top_valu": 7, "torch": [3, 4, 5, 6, 7], "toss": 5, "total": [0, 2, 3, 4, 5, 6, 7], "total_flop": 0, "total_flops_us": [3, 5, 6], "tough": 3, "toward": [6, 7], "tqdm": [3, 4, 5, 6], "track": [0, 2, 3, 4, 5, 6], "trade": 2, "tradeoff": 2, "train": [0, 2, 3, 7], "train_flops_by_batch": 2, "train_flops_by_rank": 2, "train_flops_by_seq": 2, "train_load": [0, 3, 4, 5, 6], "train_model": 0, "train_step": 0, "trainabl": [0, 3, 4, 5, 6], "trainable_param": 4, "trainer": 4, "training_flop": 2, "trajectori": [0, 1, 3, 4, 5, 6], "trajectory_id": 1, "trajectory_slid": 1, "transax": 7, "transform": [1, 2, 4, 5, 6, 7], "transpar": 1, "tree": [5, 6], "trend": [3, 5, 6], "tri": [3, 4, 5, 6, 7], "trial": 3, "trip": 0, "true": [0, 1, 2, 3, 4, 5, 6, 7], "truli": 6, "trust": 4, "trust_remote_cod": [1, 3, 4, 5, 6, 7], "truth": [3, 5, 6], "try": [3, 5, 6], "tune": [0, 2, 3, 4, 5, 6], "tupl": [0, 1], "tutori": 4, "twinkl": 6, "twirl": 5, "two": [1, 4, 5, 6], "txt": 0, "type": [0, 1, 4, 5], "u": [1, 2, 3, 5, 6], "uh": 5, "uncertainti": 6, "under": [0, 6], "underli": 3, "understand": [0, 1, 3, 5, 6], "unend": 5, "unexpect": [3, 4, 6], "unfold": [5, 6], "unifi": 7, "uniqu": 6, "univers": [4, 5, 6], "unknown": 6, "unlik": 1, "unmerg": [0, 4, 5, 6], "unmerge_lora_weight": 0, "unrel": 3, "unseen": 6, "unsqueez": [3, 5, 6], "unsupport": 4, "until": [3, 5, 6], "untold": [3, 5], "untrain": [0, 5, 6], "up": [0, 2, 3, 5, 6, 7], "updat": [3, 5, 6], "upon": 6, "upper": [3, 5, 6], "us": [0, 1, 2, 3, 4, 5, 6], "usag": [0, 2, 3, 5, 6], "user": [0, 3, 4, 5, 6, 7], "userwarn": 7, "util": [3, 4, 5, 6], "v": [1, 2, 3, 5, 6], "v0_8": 1, "v_proj": [4, 5, 6], "val": [3, 4, 5, 6, 7], "val_load": [0, 3, 4, 5, 6], "val_siz": [0, 3, 4, 5, 6], "valid": [0, 3, 4, 5, 6], "valu": [0, 1, 2, 3, 4, 5, 6, 7], "valuabl": 3, "valueerror": 0, "vari": [3, 5, 6], "variabl": 1, "varianc": 2, "variat": 6, "varieti": 6, "variou": 0, "vast": [5, 6], "vat": [4, 7], "ve": [1, 3, 5, 6], "venv": [0, 7], "verbos": [0, 2, 3, 5, 6], "veri": 3, "vers": 5, "version": [4, 6], "verticalalign": 7, "via": 2, "vibrant": 5, "view": [1, 2, 3, 4, 5, 6, 7], "visual": [0, 2, 3, 5, 6], "vivid": [3, 5], "vocab_s": [2, 3, 4, 5, 6], "vocabulari": [0, 2], "volterra": [0, 3, 5, 6], "vowel": 5, "wa": [0, 1, 2, 3, 4, 5, 6, 7], "wai": [0, 3, 4, 5, 6], "wake": [3, 5, 6], "walk": [3, 6], "wall": 3, "wandb": [0, 4], "wander": [5, 6], "want": [3, 5, 6], "warmth": 3, "warn": 4, "water": 5, "wave": 6, "wb": [5, 6], "we": [0, 1, 2, 3, 4, 5, 6, 7], "weak": 3, "weav": [5, 6], "web": 6, "weight": [2, 4, 5, 6], "weight_decai": 0, "weights_onli": [4, 5, 6, 7], "weightsunpickl": 4, "well": [1, 3, 5, 6], "were": [0, 3, 5], "what": [3, 4, 5, 6], "when": [2, 3, 5, 6], "where": [0, 2, 3, 5, 6], "wherea": 3, "whether": [0, 3], "which": [1, 2, 3, 4, 5, 6, 7], "while": [0, 3, 4, 5, 6], "whisper": [5, 6], "white": 1, "whitegrid": [1, 7], "who": [3, 5, 6], "whole": [3, 6], "why": 5, "wide": [3, 6], "widget": 1, "wind": [5, 6], "window": [0, 3, 4, 5, 6], "wing": 3, "wisdom": [3, 6], "wise": [2, 5], "within": [0, 1, 2, 3, 5, 6], "without": [0, 3, 4, 5, 6], "wonder": [5, 6], "word": [3, 5, 6], "work": [0, 1, 3, 4, 5, 6, 7], "world": [3, 5, 6], "worth": [3, 5], "would": [3, 5], "woven": [3, 5, 6], "wow": 3, "write": [3, 5, 6], "written": 6, "x": [0, 1, 2, 3, 4, 5, 6, 7], "xlabel": [1, 2], "xy": 7, "xytext": 7, "y": [2, 3, 5, 6, 7], "y_": 2, "yearn": 3, "yellow": 2, "yesterdai": 6, "yet": [5, 6], "yield": 3, "ylabel": [1, 2], "ym429": 4, "yml": 0, "yoo": 5, "you": [0, 3, 4, 5, 6], "your": [3, 6], "yuch": [4, 7], "zag": [3, 5, 6], "zero": [0, 4], "zig": [3, 5, 6], "zip": [1, 3, 5, 6, 7], "zorder": 1, "\u03b7": 0, "\u5728\u68a6\u4e2d\u5bfb\u89c5": 5, "\u5728\u8fd9\u7247\u65e0\u57a0\u7684\u5929\u5730\u95f4": 5, "\u6211\u4eec\u5bfb\u627e\u90a3\u9065\u8fdc\u7684\u68a6\u60f3": 5, "\u6bcf\u4e00\u7f15\u5149": 5, "\u6bcf\u4e00\u9897\u661f": 5, "\u76f4\u5230\u68a6\u9192": 5, "\u800c\u6bcf\u4e00\u6b21\u547c\u5438": 5, "\u8fd9\u662f\u4e00\u573a\u6f2b\u957f\u7684\u65c5\u7a0b": 5, "\u90fd\u627f\u8f7d\u7740\u8bb0\u5fc6": 5, "\u90fd\u662f\u6211\u4eec\u7075\u9b42\u7684\u8bd7\u7bc7": 5}, "titles": ["Time Series Forecasting with Qwen2.5-0.5B LLM", "Lotka-Volterra Dataset Exploration &amp; LLMTIME Preprocessing", "Understanding FLOPS Calculation for Qwen2.5 Models", "Evaluating Untrained LLM Performance on Time Series Forecasting", "Train LoRA-LLM", "Evaluating Trained LLM Performance on Time Series Forecasting", "Evaluating Fully Trained LLM Performance on Time Series Forecasting", "LM Bias Weight Visualization"], "titleterms": {"0": 0, "1": 2, "2": 2, "3": 2, "4": 2, "5": [0, 1, 2], "5b": 0, "6": 2, "7": 2, "adapt": 2, "addit": 1, "analysi": [2, 3, 5, 6], "api": 0, "appendix": 1, "architectur": 2, "attent": 2, "bia": 7, "breakdown": 2, "budget": 2, "calcul": [0, 2], "catastroph": 3, "complet": 1, "compon": 2, "conclus": [1, 2], "connect": 2, "cost": 2, "data": [0, 3, 5, 6], "dataset": 1, "defin": 2, "detoken": 1, "differ": 2, "dynam": 1, "evalu": [3, 5, 6], "experi": 0, "explor": 1, "feed": 2, "find": 0, "flop": [0, 2, 3, 5, 6], "forecast": [0, 3, 5, 6], "forget": 3, "format": 1, "forward": 2, "full": 2, "fulli": 6, "head": 2, "implement": 1, "improv": 4, "indic": 0, "instal": 0, "interact": 1, "introduct": 3, "jupyt": 0, "kei": 2, "languag": 2, "llm": [0, 3, 4, 5, 6], "llmtime": 1, "lm": 7, "lora": [0, 2, 4], "loss": 2, "lotka": 1, "method": 3, "model": [2, 4], "modul": 0, "multi": 2, "network": 2, "notebook": 0, "numericalprocessor": 1, "oper": 2, "overview": 1, "pad": 3, "paramet": 2, "perform": [3, 5, 6], "pipelin": [0, 1], "plan": 2, "potenti": 3, "predat": 1, "prei": 1, "prepar": [3, 5, 6], "preprocess": 1, "preprocessor": 0, "project": 0, "qwen2": [0, 1, 2], "refer": 0, "represent": 1, "residu": 2, "result": [0, 3, 5, 6], "rmsnorm": 2, "round": 1, "sampl": 1, "scale": [1, 2], "scheme": 1, "seri": [0, 3, 5, 6], "setup": 0, "shot": [3, 5, 6], "string": 1, "structur": 0, "tabl": 0, "test": 1, "time": [0, 3, 5, 6], "token": [1, 3], "train": [4, 5, 6], "trainer": 0, "trip": 1, "understand": 2, "untrain": 3, "visual": [1, 7], "volterra": 1, "weight": [0, 7], "zero": [3, 5, 6]}})