

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Evaluating Untrained LLM Performance on Time Series Forecasting &mdash; Time Series Forecasting with LLMs beta documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=a6e103b4" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=f0d2c090"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Train LoRA-LLM" href="4_train_lora_llm.html" />
    <link rel="prev" title="Understanding FLOPS Calculation for Qwen2.5 Models" href="2_flops_calculation.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Time Series Forecasting with LLMs
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Jupyter Notebooks</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="1_dataset_preprocess.html">Lotka-Volterra Dataset Exploration &amp; LLMTIME Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_flops_calculation.html">Understanding FLOPS Calculation for Qwen2.5 Models</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Evaluating Untrained LLM Performance on Time Series Forecasting</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Data-Preparation">Data Preparation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Zero-Shot-Forecasting-Evaluation">Zero-Shot Forecasting Evaluation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#Flops-Analysis">Flops Analysis</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#Results-Analysis">Results Analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Potential-Catastrophic-Forgetting">Potential Catastrophic Forgetting</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Tokenization-Padding-Methods">Tokenization Padding Methods</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="4_train_lora_llm.html">Train LoRA-LLM</a></li>
<li class="toctree-l1"><a class="reference internal" href="5_initial_train_behaviour.html">Evaluating Trained LLM Performance on Time Series Forecasting</a></li>
<li class="toctree-l1"><a class="reference internal" href="6_fully_trained_behaviour.html">Evaluating Fully Trained LLM Performance on Time Series Forecasting</a></li>
<li class="toctree-l1"><a class="reference internal" href="6_fully_trained_behaviour.html#Flops-Analysis">Flops Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="7_weight_visualize.html">LM Bias Weight Visualization</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Time Series Forecasting with LLMs</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Evaluating Untrained LLM Performance on Time Series Forecasting</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/notebooks/3_untrained_behaviour.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="admonition note">
<p class="admonition-title">Note</p>
<p>This page was generated from a Jupyter notebook.
<a class="reference external" href="https://github.com/yourusername/time_series_llm/blob/main/notebooks3_untrained_behaviour.ipynb">View the original notebook</a></p>
</div>
<section id="Evaluating-Untrained-LLM-Performance-on-Time-Series-Forecasting">
<h1>Evaluating Untrained LLM Performance on Time Series Forecasting<a class="headerlink" href="#Evaluating-Untrained-LLM-Performance-on-Time-Series-Forecasting" title="Link to this heading"></a></h1>
<section id="Introduction">
<h2>Introduction<a class="headerlink" href="#Introduction" title="Link to this heading"></a></h2>
<p>This notebook examines the zero-shot performance of the Qwen2.5-0.5B-Instruct model on predator-prey time series forecasting without any fine-tuning. As established by Gruver et al. (2023), large language models contain implicit capabilities for time series forecasting due to their pre-training on diverse numerical data. Before investing computational resources in fine-tuning, we need to establish a robust baseline of the model’s inherent capabilities.</p>
<p>This baseline serves multiple purposes:</p>
<ol class="arabic simple">
<li><p>Establishes a performance floor for comparison with fine-tuned models</p></li>
<li><p>Reveals whether the LLMTIME preprocessing scheme is effective</p></li>
<li><p>Helps identify specific forecasting weaknesses to target during fine-tuning</p></li>
<li><p>Informs optimal hyperparameter choices for the subsequent LoRA adaptation</p></li>
</ol>
<p>We’ll measure performance using Mean Squared Error (MSE) and Mean Absolute Error (MAE) metrics across different context window lengths.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>


<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">gc</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">h5py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="vm">__name__</span><span class="p">),</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">pardir</span><span class="p">,</span> <span class="s1">&#39;src&#39;</span><span class="p">)))</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">get_flops</span><span class="w"> </span><span class="kn">import</span> <span class="n">QwenFlopsCalculator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">get_data</span><span class="w"> </span><span class="kn">import</span> <span class="n">LotkaVolterraDataset</span><span class="p">,</span> <span class="n">DataMaster</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">preprocessor</span><span class="w"> </span><span class="kn">import</span> <span class="n">NumericalProcessor</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;loading model&quot;</span><span class="p">)</span>
<span class="c1"># models</span>
<span class="k">def</span><span class="w"> </span><span class="nf">load_qwen</span><span class="p">():</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;Qwen/Qwen2.5-0.5B-Instruct&quot;</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Freeze all parameters except LM head bias</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Add trainable bias to logits</span>
    <span class="k">assert</span> <span class="n">model</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span>
    <span class="n">model</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span>

<span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">load_qwen</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;model Loaded&quot;</span><span class="p">)</span>

<span class="c1"># some nice function for GPU Training</span>
<span class="k">def</span><span class="w"> </span><span class="nf">clear_memory</span><span class="p">():</span>
    <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">ipc_collect</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">reset_peak_memory_stats</span><span class="p">()</span>

<span class="c1"># device</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

<span class="c1"># random seed</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
loading model
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
model Loaded
</pre></div></div>
</div>
</section>
<section id="Data-Preparation">
<h2>Data Preparation<a class="headerlink" href="#Data-Preparation" title="Link to this heading"></a></h2>
<p>For efficient experimentation, we use the <code class="docutils literal notranslate"><span class="pre">DataMaster</span></code> class which handles:</p>
<ul class="simple">
<li><p>Loading the Lotka-Volterra predator-prey time series data</p></li>
<li><p>Preprocessing numerical data using the LLMTIME scheme</p></li>
<li><p>Creating appropriate train/validation/test splits</p></li>
<li><p>Building PyTorch DataLoaders with configurable parameters</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">experiment_fraction=0.1</span></code> parameter allows us to work with a smaller subset of data (10%) for faster iteration during development. In our final evaluation, we can scale this up to use the complete dataset by setting it to 1.0.</p>
<p>The context length parameter controls how much historical data the model sees when making predictions. Varying this parameter helps us understand the model’s sensitivity to context window size, which is important for both performance optimization and FLOPS budget management.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># %%</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="c1"># Load the data</span>


<span class="c1"># data folder:</span>
<span class="n">DATA_FOLDER</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="vm">__name__</span><span class="p">),</span> <span class="s1">&#39;..&#39;</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">)</span>


<span class="k">with</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_FOLDER</span><span class="p">,</span> <span class="s1">&#39;lotka_volterra_data.h5&#39;</span><span class="p">),</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="c1"># Access the full dataset</span>
    <span class="n">trajectories</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="s2">&quot;trajectories&quot;</span><span class="p">][:]</span>
    <span class="n">time_points</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="s2">&quot;time&quot;</span><span class="p">][:]</span>

<span class="c1"># Here we are only using a small fraction of the data for the experiment</span>
<span class="n">data_master</span> <span class="o">=</span> <span class="n">DataMaster</span><span class="p">(</span>
    <span class="n">tokenizer</span><span class="p">,</span> <span class="n">trajectories</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">val_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">experiment_fraction</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Zero-Shot-Forecasting-Evaluation">
<h2>Zero-Shot Forecasting Evaluation<a class="headerlink" href="#Zero-Shot-Forecasting-Evaluation" title="Link to this heading"></a></h2>
<p>Now we evaluate the untrained Qwen2.5-0.5B model on predator-prey time series forecasting. The evaluation procedure:</p>
<ol class="arabic simple">
<li><p><strong>Sequential Prediction</strong>: We provide the model with initial context (e.g., 128 tokens) and let it autoregressively generate predictions</p></li>
<li><p><strong>Termination Criteria</strong>: The model generates tokens until either:</p>
<ul class="simple">
<li><p>It produces a maximum of <code class="docutils literal notranslate"><span class="pre">semi_colon_max</span></code> semicolons (<strong>indicating how many complete timestamps of (predator, prey) pairs we want to forecast</strong>)</p></li>
</ul>
</li>
<li><p><strong>Metric Calculation</strong>: We decode the generated tokens back to numerical values and compute:</p>
<ul class="simple">
<li><p>Mean Squared Error (MSE): Measures average squared difference between predictions and ground truth</p></li>
<li><p>Mean Absolute Error (MAE): Measures average absolute difference</p></li>
<li><p>Time-indexed metrics: Track how errors evolve over sequential prediction steps</p></li>
</ul>
</li>
</ol>
<p>We evaluate across multiple context window sizes (128, 512, 768) to understand how the amount of historical context affects forecasting accuracy. This gives us insights into the model’s inherent temporal reasoning capabilities and memory limitations.</p>
<p>All FLOPS usage is carefully tracked to ensure we stay within our computational budget of 10^17 FLOPS.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># %%</span>

<span class="n">processor</span> <span class="o">=</span> <span class="n">data_master</span><span class="o">.</span><span class="n">processor</span>

<span class="n">flops_logger</span> <span class="o">=</span> <span class="n">QwenFlopsCalculator</span><span class="p">()</span>


<span class="n">Total_flops_used</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">Flops_counter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>


<span class="n">logged_metrics</span> <span class="o">=</span> <span class="p">{}</span>

<span class="k">for</span> <span class="n">context_length</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">768</span><span class="p">):</span>
    <span class="n">semi_colon_max</span> <span class="o">=</span> <span class="mi">6</span>
    <span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;MSE_</span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;MAE_</span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;MSE_</span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s1">_per_time&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;MAE_</span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s1">_per_time&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;CE_</span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s1">_per_token&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>


    <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">test_loader</span> <span class="o">=</span> <span class="n">data_master</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span>
        <span class="n">context_length</span><span class="o">=</span><span class="n">context_length</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">experiment</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">target_eval_pairs</span> <span class="o">=</span> <span class="n">semi_colon_max</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="p">)</span>

    <span class="n">loader</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">leave</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">loader</span><span class="p">:</span>

        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># we allow the model infer until (reached 2 * target length) or the model predict the end token (semi-colon token -&gt; 26)</span>
        <span class="n">max_length</span> <span class="o">=</span> <span class="n">semi_colon_max</span> <span class="o">*</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">original_length</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">semi_colon_count</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">per_step_ce</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_length</span><span class="p">):</span>

                <span class="n">flops_logger</span><span class="o">.</span><span class="n">log_flops</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="n">context_length</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">inference</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">description</span> <span class="o">=</span> <span class="s2">&quot;MSE Untrained Evaluation&quot;</span><span class="p">)</span>

                <span class="c1"># only use context length size of input_ids to predict the next token</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[:,</span> <span class="o">-</span><span class="n">context_length</span><span class="p">:])</span>
                <span class="n">next_token_logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
                <span class="n">next_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">next_token_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">next_token</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

                <span class="c1"># get the CE loss</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">next_token_logits</span><span class="p">,</span> <span class="n">target</span><span class="p">[:,</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">original_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>
                <span class="n">per_step_ce</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

                <span class="k">if</span> <span class="n">next_token</span> <span class="o">==</span> <span class="mi">26</span><span class="p">:</span>
                    <span class="n">semi_colon_count</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="k">if</span> <span class="n">semi_colon_count</span> <span class="o">==</span> <span class="n">semi_colon_max</span><span class="p">:</span>
                        <span class="k">break</span>

        <span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;CE_</span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s1">_per_token&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">per_step_ce</span><span class="p">)</span>


        <span class="c1"># convert to numpy</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">target</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

        <span class="c1"># postprocess</span>
        <span class="n">predicted_values</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">decode_to_string</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[</span><span class="n">original_length</span><span class="p">:])</span>
        <span class="n">target_values</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">decode_to_string</span><span class="p">(</span><span class="n">target</span><span class="p">)</span>

        <span class="c1"># for both get the first semi-colon and use any value after that</span>
        <span class="n">predicted_values</span> <span class="o">=</span> <span class="n">predicted_values</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;;&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:</span><span class="n">semi_colon_count</span><span class="p">]</span>
        <span class="n">predicted_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">pred_val</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">pred_val</span> <span class="ow">in</span> <span class="n">predicted_values</span><span class="p">]</span>
        <span class="n">predicted_values</span> <span class="o">=</span> <span class="p">[[</span><span class="nb">float</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">pred_val</span><span class="p">]</span> <span class="k">for</span> <span class="n">pred_val</span> <span class="ow">in</span> <span class="n">predicted_values</span><span class="p">]</span>
        <span class="n">predicted_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">predicted_values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">predicted_values</span> <span class="o">=</span> <span class="n">predicted_values</span> <span class="o">/</span> <span class="n">processor</span><span class="o">.</span><span class="n">scaler</span>

        <span class="n">target_values</span> <span class="o">=</span> <span class="n">target_values</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;;&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:</span><span class="n">semi_colon_count</span><span class="p">]</span>
        <span class="n">target_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">tar_val</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">tar_val</span> <span class="ow">in</span> <span class="n">target_values</span><span class="p">]</span>
        <span class="n">target_values</span> <span class="o">=</span> <span class="p">[[</span><span class="nb">float</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">tar_val</span><span class="p">]</span> <span class="k">for</span> <span class="n">tar_val</span> <span class="ow">in</span> <span class="n">target_values</span><span class="p">]</span>
        <span class="n">target_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">target_values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">target_values</span> <span class="o">=</span> <span class="n">target_values</span> <span class="o">/</span> <span class="n">processor</span><span class="o">.</span><span class="n">scaler</span>


        <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">predicted_values</span> <span class="o">-</span> <span class="n">target_values</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">mae</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">predicted_values</span> <span class="o">-</span> <span class="n">target_values</span><span class="p">))</span>

        <span class="n">mse_per_time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">predicted_values</span> <span class="o">-</span> <span class="n">target_values</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">mae_per_time</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">predicted_values</span> <span class="o">-</span> <span class="n">target_values</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;MSE_</span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s1">_per_time&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mse_per_time</span><span class="p">)</span>
        <span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;MAE_</span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s1">_per_time&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mae_per_time</span><span class="p">)</span>

        <span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;MSE_</span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>
        <span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;MAE_</span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mae</span><span class="p">)</span>

        <span class="n">loader</span><span class="o">.</span><span class="n">desc</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;MSE: </span><span class="si">{</span><span class="n">mse</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">, MAE: </span><span class="si">{</span><span class="n">mae</span><span class="si">:</span><span class="s2">.6f</span><span class="si">}</span><span class="s2">&quot;</span>



    <span class="n">flops_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">flops_logger</span><span class="o">.</span><span class="n">log_file</span><span class="p">)</span>
    <span class="n">current_exp_flops</span> <span class="o">=</span> <span class="n">flops_df</span><span class="p">[</span><span class="n">flops_df</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">flops_logger</span><span class="o">.</span><span class="n">log_name</span><span class="p">]</span>
    <span class="n">Total_flops_used</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">current_exp_flops</span><span class="o">.</span><span class="n">flops</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">Flops_counter</span>
    <span class="p">)</span>
    <span class="n">Flops_counter</span> <span class="o">=</span> <span class="n">current_exp_flops</span><span class="o">.</span><span class="n">flops</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>


<span class="c1"># pad the perstep CE to the same length</span>
<span class="n">max_length</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;CE_128_per_token&#39;</span><span class="p">])</span>
<span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">logged_metrics</span><span class="p">:</span>
    <span class="k">if</span> <span class="s1">&#39;CE&#39;</span> <span class="ow">in</span> <span class="n">key</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">logged_metrics</span><span class="p">[</span><span class="n">key</span><span class="p">])):</span>
            <span class="n">logged_metrics</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">max_length</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">logged_metrics</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">i</span><span class="p">]))</span>


<span class="c1"># print the Total_flops_used</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">flops</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">Total_flops_used</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total FLOPS used for context length </span><span class="si">{</span><span class="p">[</span><span class="mi">128</span><span class="p">,</span><span class="w"> </span><span class="mi">512</span><span class="p">,</span><span class="w"> </span><span class="mi">768</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">flops</span><span class="si">:</span><span class="s2">.3e</span><span class="si">}</span><span class="s2">, -- [</span><span class="si">{</span><span class="n">flops</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">1e17</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> percent of budget]&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 3200 chunks from 800 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 400 chunks from 100 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 400 chunks from 100 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Sanity check:   0%|          | 0/3 [00:00&lt;?, ?it/s]
Sanity check Train:   0%|          | 0/3200 [00:00&lt;?, ?it/s]
Sanity check Train:   0%|          | 1/3200 [00:00&lt;14:38,  3.64it/s]
Sanity check Train: 100%|██████████| 3200/3200 [00:00&lt;00:00, 7758.29it/s]
Sanity check:  33%|███▎      | 1/3 [00:00&lt;00:00,  2.41it/s]
Sanity check Val: 100%|██████████| 400/400 [00:00&lt;00:00, 23355.54it/s]

Sanity check Test: 100%|██████████| 400/400 [00:00&lt;00:00, 23348.06it/s]

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 1604 chunks from 800 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 200 chunks from 100 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 200 chunks from 100 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Sanity check:   0%|          | 0/3 [00:00&lt;?, ?it/s]
Sanity check Train: 100%|██████████| 1604/1604 [00:00&lt;00:00, 23558.39it/s]

Sanity check Val: 100%|██████████| 200/200 [00:00&lt;00:00, 23430.56it/s]

Sanity check Test: 100%|██████████| 200/200 [00:00&lt;00:00, 23514.63it/s]

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 804 chunks from 800 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 100 chunks from 100 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 100 chunks from 100 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Sanity check:   0%|          | 0/3 [00:00&lt;?, ?it/s]
Sanity check Train: 100%|██████████| 804/804 [00:00&lt;00:00, 23708.13it/s]

Sanity check Val: 100%|██████████| 100/100 [00:00&lt;00:00, 21374.43it/s]

Sanity check Test: 100%|██████████| 100/100 [00:00&lt;00:00, 21374.43it/s]

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Total FLOPS used for context length 128: 3.506e+15, -- [3.506 percent of budget]
Total FLOPS used for context length 512: 7.326e+15, -- [7.326 percent of budget]
Total FLOPS used for context length 768: 5.385e+15, -- [5.385 percent of budget]
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<p>Now, we can show the results of the evaluation. We will display the MSE and MAE for each context window size, as well as the time-indexed metrics to understand how the model’s forecasting performance degrades over time.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">context_length</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">768</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Context Length: </span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="c1"># print(f&#39;CE per token: {np.mean(logged_metrics[f&quot;CE_{context_length}_per_token&quot;])}&#39;)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;MSE: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;MSE_</span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s2">_per_time&quot;</span><span class="p">])</span><span class="si">:</span><span class="s1">.6f</span><span class="si">}</span><span class="s1">, MAE: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;MAE_</span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s2">_per_time&quot;</span><span class="p">])</span><span class="si">:</span><span class="s1">.6f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;MSE per time: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;MSE_</span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s2">_per_time&quot;</span><span class="p">],</span><span class="w"> </span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;MAE per time: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;MAE_</span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s2">_per_time&quot;</span><span class="p">],</span><span class="w"> </span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">()</span>


<span class="c1"># Plot 1: MSE and MAE degradation over time for each context length</span>
<span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">context_lengths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">768</span><span class="p">]</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="s1">&#39;red&#39;</span><span class="p">]</span>
<span class="n">time_steps</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>  <span class="c1"># 0 to 4 time steps</span>

<span class="c1"># Plot MSE degradation over time</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">context_length</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">context_lengths</span><span class="p">):</span>
    <span class="n">mse_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;MSE_</span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s1">_per_time&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time_steps</span><span class="p">,</span> <span class="n">mse_values</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Context Length </span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;MSE Degradation Over Time&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Time Step&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Mean Squared Error&#39;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="c1"># Plot MAE degradation over time</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">context_length</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">context_lengths</span><span class="p">):</span>
    <span class="n">mae_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;MAE_</span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s1">_per_time&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">time_steps</span><span class="p">,</span> <span class="n">mae_values</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">&#39;Context Length </span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">ax2</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;MAE Degradation Over Time&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Time Step&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Mean Absolute Error&#39;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Plot 2: MSE and MAE vs context length</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">mse_by_context</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;MSE_</span><span class="si">{</span><span class="n">cl</span><span class="si">}</span><span class="s1">_per_time&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="k">for</span> <span class="n">cl</span> <span class="ow">in</span> <span class="n">context_lengths</span><span class="p">]</span>
<span class="n">mae_by_context</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;MAE_</span><span class="si">{</span><span class="n">cl</span><span class="si">}</span><span class="s1">_per_time&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="k">for</span> <span class="n">cl</span> <span class="ow">in</span> <span class="n">context_lengths</span><span class="p">]</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">context_lengths</span><span class="p">,</span> <span class="n">mse_by_context</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MSE&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">context_lengths</span><span class="p">,</span> <span class="n">mae_by_context</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MAE&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Error Metrics by Context Length&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Context Length&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Error Value&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">context_lengths</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<br/><br/><br/></pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
==================================================
Context Length: 128
MSE: 0.551002, MAE: 0.342673
MSE per time: [0.03231214 0.13250503 0.37468666 0.8040001  1.411504  ]
MAE per time: [0.09158203 0.19397523 0.32619426 0.47306427 0.6285472 ]

==================================================
Context Length: 512
MSE: 0.104814, MAE: 0.150884
MSE per time: [0.00767334 0.02833716 0.07586795 0.14912029 0.2630726 ]
MAE per time: [0.04772122 0.08936435 0.14351271 0.20164469 0.27217925]

==================================================
Context Length: 768
MSE: 0.069979, MAE: 0.116683
MSE per time: [0.00507598 0.01961915 0.0449815  0.09535234 0.18486528]
MAE per time: [0.03351163 0.06817318 0.10866642 0.15815355 0.21490975]

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_3_untrained_behaviour_7_1.png" src="../_images/notebooks_3_untrained_behaviour_7_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_3_untrained_behaviour_7_2.png" src="../_images/notebooks_3_untrained_behaviour_7_2.png" />
</div>
</div>
<p>Here, we can see a clear trend: as the <strong>context window size increases, the model’s forecasting performance improves</strong>. This is expected, as the model has more historical data to base its predictions on. However, the improvement is not linear, indicating that the model may struggle with long-range dependencies or memory limitations. This information will be crucial for fine-tuning the model and optimizing its performance on this task.</p>
<p>Also, <strong>as the model generates predictions further into the future, the forecasting error increases</strong>. This is expected, as the model is making predictions based on its own generated outputs, which may introduce compounding errors. This trend is important to consider when designing forecasting systems that rely on autoregressive models.</p>
<p>Finally, for the cross-entropy loss, <strong>we can see that there is a interesting zig-zag pattern</strong>. Notice that the loss sometimes reaches zero, and then jumps back up. <strong>The zero is due to the fact that the model have learnt that after a few steps, there must be a semicolon, and then the pattern repeats</strong>. The semi-colon, the comma and the period are quite predictable tokens, and the model can learn to generalize them quite well. However, for the numerical values, the model struggles more, and the
loss increases as the model tries to predict into the future.</p>
<p>When we apply a moving average of 10 steps to the loss, we can see that the zig-zag pattern is smoothed out, and we can see a more clear trend of the loss increasing over time. This is a common technique to visualize trends in noisy data, and can help us understand the overall performance of the model better. We can additionally see that again the model performs better with a larger context window, as it has more information to base its predictions on.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">flops_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">flops_logger</span><span class="o">.</span><span class="n">log_file</span><span class="p">)</span>
<span class="n">flops_used</span> <span class="o">=</span> <span class="n">flops_df</span><span class="p">[</span><span class="n">flops_df</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">flops_logger</span><span class="o">.</span><span class="n">log_name</span><span class="p">]</span><span class="o">.</span><span class="n">flops</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;FLOPS used: </span><span class="si">{</span><span class="n">flops_used</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2"> or 1e</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="n">flops_used</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">. Using </span><span class="si">{</span><span class="n">flops_used</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">1e17</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">% of the Budget&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
FLOPS used: 16216687344171552 or 1e16.21. Using 16.22% of the Budget
</pre></div></div>
</div>
<section id="Flops-Analysis">
<h3>Flops Analysis<a class="headerlink" href="#Flops-Analysis" title="Link to this heading"></a></h3>
<p>Our analysis shows that even using only 1% of the data (10 % of the evaluation set, where the evaluation set is 10% of the entire dataset) already consumes 1.3% of the total computational budget, meaning each validation experiment costs approximately 0.4% of our budget. Since validation will be run multiple times in an experiment, and we have at least 12 experiments planned (3 [rank search] × 3 [learning rate search] + 3 [context length search]), this approach to validation is computationally
expensive.</p>
<p>Therefore, I propose reducing the forecast horizon from 5 to 3 timestamps. This modification will decrease FLOPS usage by approximately 40%, making our experiments significantly more efficient.</p>
<p>This decision is supported by our observations: for the first 2 timestamps, MSE and MAE are relatively similar across different context lengths. However, as error propagates, the third timestamp is where performance between models begins to meaningfully diverge. The plots above demonstrate a clear difference in MSE and MAE values at the third timestamp, making it a suitable evaluation point while conserving computational resources.</p>
<p>Below, we show the updated results for the 3-timestamp forecast horizon.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Plot 2: MSE and MAE vs context length</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="n">mse_by_context</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;MSE_</span><span class="si">{</span><span class="n">cl</span><span class="si">}</span><span class="s1">_per_time&#39;</span><span class="p">])[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">])</span> <span class="k">for</span> <span class="n">cl</span> <span class="ow">in</span> <span class="n">context_lengths</span><span class="p">]</span>
<span class="n">mae_by_context</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;MAE_</span><span class="si">{</span><span class="n">cl</span><span class="si">}</span><span class="s1">_per_time&#39;</span><span class="p">])[:,</span> <span class="p">:</span><span class="mi">3</span><span class="p">])</span> <span class="k">for</span> <span class="n">cl</span> <span class="ow">in</span> <span class="n">context_lengths</span><span class="p">]</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">context_lengths</span><span class="p">,</span> <span class="n">mse_by_context</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MSE&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">context_lengths</span><span class="p">,</span> <span class="n">mae_by_context</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;MAE&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Error Metrics by Context Length&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Context Length&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Error Value&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">context_lengths</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="k">for</span> <span class="n">context_length</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">768</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Context Length: </span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;, &quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s1">&#39;MSE: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;MSE_</span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s2">_per_time&quot;</span><span class="p">],</span><span class="w"> </span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[:</span><span class="mi">3</span><span class="p">])</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s2">&quot;, &quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span>
        <span class="sa">f</span><span class="s1">&#39;MAE: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">logged_metrics</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;MAE_</span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="s2">_per_time&quot;</span><span class="p">],</span><span class="w"> </span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)[:</span><span class="mi">3</span><span class="p">])</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_3_untrained_behaviour_11_0.png" src="../_images/notebooks_3_untrained_behaviour_11_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
==================================================
Context Length: 128, MSE: 0.180, MAE: 0.204
==================================================
Context Length: 512, MSE: 0.037, MAE: 0.094
==================================================
Context Length: 768, MSE: 0.023, MAE: 0.070
</pre></div></div>
</div>
</section>
</section>
<section id="Results-Analysis">
<h2>Results Analysis<a class="headerlink" href="#Results-Analysis" title="Link to this heading"></a></h2>
<p>The metrics above reveal how accurately the untrained Qwen2.5-0.5B model can forecast predator-prey dynamics. Several observations:</p>
<ol class="arabic simple">
<li><p><strong>Context Length Impact</strong>: We can see how prediction accuracy varies with different context window sizes.</p></li>
<li><p><strong>Error Progression</strong>: The per-timestep metrics show how errors accumulate (or potentially stabilize) as the model predicts further into the future.</p></li>
<li><p><strong>Overall Performance</strong>: The aggregate MSE and MAE values establish our baseline performance, which we’ll aim to improve through LoRA fine-tuning.</p></li>
<li><p><strong>FLOPS Accounting</strong>: We’ve carefully tracked all computational costs to ensure our experiments remain within budget constraints.</p></li>
</ol>
<p>These baseline results inform our fine-tuning strategy by highlighting:</p>
<ul class="simple">
<li><p>The optimal context window size for balancing performance and computational efficiency</p></li>
<li><p>The model’s inherent limitations on temporal forecasting</p></li>
<li><p>Specific patterns where the model struggles most (which may require dedicated attention during fine-tuning)</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">datas</span> <span class="o">=</span> <span class="p">{}</span>

<span class="n">predicted</span> <span class="o">=</span> <span class="p">{}</span>

<span class="n">semi_colon_max</span> <span class="o">=</span> <span class="mi">20</span>
<span class="k">for</span> <span class="n">context_length</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">768</span><span class="p">):</span>
    <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">test_loader</span> <span class="o">=</span> <span class="n">data_master</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span>
        <span class="n">context_length</span><span class="o">=</span><span class="n">context_length</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">experiment</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">target_eval_pairs</span> <span class="o">=</span> <span class="n">semi_colon_max</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="p">)</span>
    <span class="n">temp_test_loader_active</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span>
    <span class="n">datas</span><span class="p">[</span><span class="n">context_length</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">next</span><span class="p">(</span><span class="n">temp_test_loader_active</span><span class="p">)]</span>
    <span class="n">datas</span><span class="p">[</span><span class="n">context_length</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="n">temp_test_loader_active</span><span class="p">))</span>



<span class="n">processor</span> <span class="o">=</span> <span class="n">data_master</span><span class="o">.</span><span class="n">processor</span>

<span class="n">flops_logger</span> <span class="o">=</span> <span class="n">QwenFlopsCalculator</span><span class="p">()</span>


<span class="n">Total_flops_used</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">Flops_counter</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">result</span> <span class="o">=</span> <span class="p">{}</span>



<span class="k">for</span> <span class="n">context_length</span> <span class="ow">in</span> <span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">768</span><span class="p">):</span>
    <span class="n">result</span><span class="p">[</span><span class="n">context_length</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">test_loader</span> <span class="o">=</span> <span class="n">data_master</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span>
        <span class="n">context_length</span><span class="o">=</span><span class="n">context_length</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">experiment</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">target_eval_pairs</span> <span class="o">=</span> <span class="n">semi_colon_max</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="p">)</span>
    <span class="c1"># claer tqdm instance</span>
    <span class="n">tqdm</span><span class="o">.</span><span class="n">_instances</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">datas</span><span class="p">[</span><span class="n">context_length</span><span class="p">]:</span>

        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="c1"># we allow the model infer until (reached 2 * target length) or the model predict the end token (semi-colon token -&gt; 26)</span>
        <span class="n">max_length</span> <span class="o">=</span> <span class="n">semi_colon_max</span> <span class="o">*</span> <span class="n">target</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">original_length</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">semi_colon_count</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="n">per_step_ce</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_length</span><span class="p">):</span>

                <span class="n">flops_logger</span><span class="o">.</span><span class="n">log_flops</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="n">context_length</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">inference</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">description</span> <span class="o">=</span> <span class="s2">&quot;MSE Untrained Evaluation&quot;</span><span class="p">)</span>

                <span class="c1"># only use context length size of input_ids to predict the next token</span>
                <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[:,</span> <span class="o">-</span><span class="n">context_length</span><span class="p">:])</span>
                <span class="n">next_token_logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
                <span class="n">next_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">next_token_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
                <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">next_token</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

                <span class="c1"># get the CE loss</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">cross_entropy</span><span class="p">(</span><span class="n">next_token_logits</span><span class="p">,</span> <span class="n">target</span><span class="p">[:,</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">original_length</span> <span class="o">-</span> <span class="mi">1</span><span class="p">])</span>
                <span class="n">per_step_ce</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

                <span class="k">if</span> <span class="n">next_token</span> <span class="o">==</span> <span class="mi">26</span><span class="p">:</span>
                    <span class="n">semi_colon_count</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="k">if</span> <span class="n">semi_colon_count</span> <span class="o">==</span> <span class="n">semi_colon_max</span><span class="p">:</span>
                        <span class="k">break</span>

        <span class="n">result</span><span class="p">[</span><span class="n">context_length</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[:,</span> <span class="n">original_length</span><span class="p">:]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>


    <span class="n">flops_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">flops_logger</span><span class="o">.</span><span class="n">log_file</span><span class="p">)</span>
    <span class="n">current_exp_flops</span> <span class="o">=</span> <span class="n">flops_df</span><span class="p">[</span><span class="n">flops_df</span><span class="p">[</span><span class="s1">&#39;name&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">flops_logger</span><span class="o">.</span><span class="n">log_name</span><span class="p">]</span>
    <span class="n">Total_flops_used</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">current_exp_flops</span><span class="o">.</span><span class="n">flops</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">-</span> <span class="n">Flops_counter</span>
    <span class="p">)</span>
    <span class="n">Flops_counter</span> <span class="o">=</span> <span class="n">current_exp_flops</span><span class="o">.</span><span class="n">flops</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>


<span class="c1"># print the Total_flops_used</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">flops</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">Total_flops_used</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total FLOPS used for context length </span><span class="si">{</span><span class="p">[</span><span class="mi">128</span><span class="p">,</span><span class="w"> </span><span class="mi">512</span><span class="p">,</span><span class="w"> </span><span class="mi">768</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">flops</span><span class="si">:</span><span class="s2">.3e</span><span class="si">}</span><span class="s2">, -- [</span><span class="si">{</span><span class="n">flops</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">1e17</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> percent of budget]&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 3200 chunks from 800 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 300 chunks from 100 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 300 chunks from 100 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Sanity check:   0%|          | 0/3 [00:00&lt;?, ?it/s]
Sanity check Train:   0%|          | 0/3200 [00:00&lt;?, ?it/s]
Sanity check Train: 100%|██████████| 3200/3200 [00:00&lt;00:00, 24168.44it/s]
Sanity check:  33%|███▎      | 1/3 [00:00&lt;00:00,  7.45it/s]
Sanity check Val: 100%|██████████| 300/300 [00:00&lt;00:00, 23829.02it/s]

Sanity check Test: 100%|██████████| 300/300 [00:00&lt;00:00, 23666.33it/s]

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 1604 chunks from 800 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 200 chunks from 100 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 200 chunks from 100 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Sanity check:   0%|          | 0/3 [00:00&lt;?, ?it/s]
Sanity check Train: 100%|██████████| 1604/1604 [00:00&lt;00:00, 23312.43it/s]

Sanity check Val: 100%|██████████| 200/200 [00:00&lt;00:00, 22628.49it/s]

Sanity check Test: 100%|██████████| 200/200 [00:00&lt;00:00, 22891.55it/s]

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 804 chunks from 800 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 100 chunks from 100 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 100 chunks from 100 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Sanity check:   0%|          | 0/3 [00:00&lt;?, ?it/s]
Sanity check Train: 100%|██████████| 804/804 [00:00&lt;00:00, 23333.77it/s]

Sanity check Val: 100%|██████████| 100/100 [00:00&lt;00:00, 20957.90it/s]

Sanity check Test: 100%|██████████| 100/100 [00:00&lt;00:00, 20864.07it/s]

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 3200 chunks from 800 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 300 chunks from 100 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 300 chunks from 100 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Sanity check:   0%|          | 0/3 [00:00&lt;?, ?it/s]
Sanity check Train:   0%|          | 0/3200 [00:00&lt;?, ?it/s]
Sanity check Train: 100%|██████████| 3200/3200 [00:00&lt;00:00, 24507.31it/s]
Sanity check:  33%|███▎      | 1/3 [00:00&lt;00:00,  7.55it/s]
Sanity check Val: 100%|██████████| 300/300 [00:00&lt;00:00, 24143.58it/s]

Sanity check Test: 100%|██████████| 300/300 [00:00&lt;00:00, 24139.42it/s]

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 1604 chunks from 800 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 200 chunks from 100 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 200 chunks from 100 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Sanity check:   0%|          | 0/3 [00:00&lt;?, ?it/s]
Sanity check Train: 100%|██████████| 1604/1604 [00:00&lt;00:00, 24020.42it/s]

Sanity check Val: 100%|██████████| 200/200 [00:00&lt;00:00, 23627.88it/s]

Sanity check Test: 100%|██████████| 200/200 [00:00&lt;00:00, 23936.68it/s]

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 804 chunks from 800 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 100 chunks from 100 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Created 100 chunks from 100 sequences
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Sanity check:   0%|          | 0/3 [00:00&lt;?, ?it/s]
Sanity check Train: 100%|██████████| 804/804 [00:00&lt;00:00, 23316.35it/s]

Sanity check Val: 100%|██████████| 100/100 [00:00&lt;00:00, 21767.11it/s]

Sanity check Test: 100%|██████████| 100/100 [00:00&lt;00:00, 21372.25it/s]

</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Total FLOPS used for context length 128: 6.547e+13, -- [0.065 percent of budget]
Total FLOPS used for context length 512: 2.596e+14, -- [0.260 percent of budget]
Total FLOPS used for context length 768: 3.967e+14, -- [0.397 percent of budget]
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># for each</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">14</span><span class="p">))</span>
<span class="n">context_lengths</span> <span class="o">=</span> <span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">768</span><span class="p">]</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;#1f77b4&#39;</span><span class="p">,</span> <span class="s1">&#39;#ff7f0e&#39;</span><span class="p">,</span> <span class="s1">&#39;#2ca02c&#39;</span><span class="p">,</span> <span class="s1">&#39;#d62728&#39;</span><span class="p">]</span>
<span class="n">examples</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Example 1&quot;</span><span class="p">,</span> <span class="s2">&quot;Example 2&quot;</span><span class="p">]</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">context_length</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">context_lengths</span><span class="p">):</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">datas</span><span class="p">[</span><span class="n">context_length</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">d</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

        <span class="n">full_sequence</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">target</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Process data for plotting</span>
        <span class="n">full_sequence_values</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">postprocess</span><span class="p">(</span><span class="n">full_sequence</span><span class="p">)</span>
        <span class="n">input_ids_values</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">postprocess</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span>
        <span class="n">result_ids_values</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">decode_to_string</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="n">context_length</span><span class="p">][</span><span class="n">j</span><span class="p">])</span>
        <span class="c1"># Split by semicolons and process each pair</span>
        <span class="n">result_ids_values</span> <span class="o">=</span> <span class="n">result_ids_values</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;;&quot;</span><span class="p">)[</span><span class="mi">1</span><span class="p">:</span><span class="n">semi_colon_count</span><span class="p">]</span>
        <span class="n">result_ids_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">pair</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">result_ids_values</span><span class="p">]</span>
        <span class="n">result_ids_values</span> <span class="o">=</span> <span class="p">[[</span><span class="nb">float</span><span class="p">(</span><span class="n">val</span><span class="p">)</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">pair</span><span class="p">]</span> <span class="k">for</span> <span class="n">pair</span> <span class="ow">in</span> <span class="n">result_ids_values</span><span class="p">]</span>
        <span class="n">result_ids_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">result_ids_values</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="c1"># Apply scaling factor to get actual values</span>
        <span class="n">result_ids_values</span> <span class="o">=</span> <span class="n">result_ids_values</span> <span class="o">/</span> <span class="n">processor</span><span class="o">.</span><span class="n">scaler</span>      <span class="c1"># decode the values</span>
        <span class="n">result_time</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_ids_values</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">result_ids_values</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">input_ids_values</span><span class="p">))</span>

        <span class="c1"># Plot predator population</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">full_sequence_values</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ground Truth&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">input_ids_values</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Context&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">result_time</span><span class="p">,</span> <span class="n">result_ids_values</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                        <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Prediction&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

        <span class="c1"># Plot prey population</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="o">*</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">full_sequence_values</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Ground Truth&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="o">*</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">input_ids_values</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Context&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="o">*</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">result_time</span><span class="p">,</span> <span class="n">result_ids_values</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                          <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Prediction&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

        <span class="c1"># Set titles and labels</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Context Length: </span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="se">\n</span><span class="si">{</span><span class="n">examples</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="si">}</span><span class="s2"> - Predator Population&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>
        <span class="n">ax</span><span class="p">[</span><span class="n">j</span><span class="o">*</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Context Length: </span><span class="si">{</span><span class="n">context_length</span><span class="si">}</span><span class="se">\n</span><span class="si">{</span><span class="n">examples</span><span class="p">[</span><span class="n">j</span><span class="p">]</span><span class="si">}</span><span class="s2"> - Prey Population&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">)</span>

        <span class="c1"># Add grid and legend to make the plots more readable</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="p">[</span><span class="n">j</span><span class="o">*</span><span class="mi">2</span><span class="p">,</span> <span class="n">j</span><span class="o">*</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">]:</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">framealpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
            <span class="n">ax</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Population&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

            <span class="c1"># Only show x label on bottom row</span>
            <span class="k">if</span> <span class="n">row</span> <span class="o">==</span> <span class="n">j</span><span class="o">*</span><span class="mi">2</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span>
                <span class="n">ax</span><span class="p">[</span><span class="n">row</span><span class="p">,</span> <span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s1">&#39;Time Step&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Add overall title</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s1">&#39;Predator-Prey Time Series Forecasting by Context Length&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">fontweight</span><span class="o">=</span><span class="s1">&#39;bold&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="mf">0.98</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">(</span><span class="n">rect</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">0.96</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<br/><br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_3_untrained_behaviour_14_0.png" src="../_images/notebooks_3_untrained_behaviour_14_0.png" />
</div>
</div>
</section>
<section id="Potential-Catastrophic-Forgetting">
<h2>Potential Catastrophic Forgetting<a class="headerlink" href="#Potential-Catastrophic-Forgetting" title="Link to this heading"></a></h2>
<p>Fine-tuning can often lead to catastrophic forgetting, where a model loses previously acquired knowledge. To assess whether this occurs, we evaluate the model’s performance on a small set of prompts unrelated to time series forecasting. This allows us to gauge whether the model retains its general knowledge after fine-tuning. Although the prompt set is limited in size, it serves as an initial indicator of the model’s performance. If signs of catastrophic forgetting are observed, they can be
readily identified, and a larger, more comprehensive prompt set can be considered for future evaluations.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prompt_list</span> <span class="o">=</span> <span class="p">[</span>
    <span class="s2">&quot;How many r in strawberry?&quot;</span><span class="p">,</span>
    <span class="s2">&quot;what is the result of 1 + 1&quot;</span><span class="p">,</span>
    <span class="s2">&quot;what is the result of 0.12 + 3.24&quot;</span><span class="p">,</span>
    <span class="s2">&quot;0, 1, 1, 2, 3, 5, 8,&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Write a poem that uses numbers as metaphors. For instance, start with &#39;1.20, 1.31; 0.93, 0.98&#39; and explore what these figures might mean in life.&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Craft a poem that tells a story of dreams and memories, using punctuation naturally to evoke a rhythmic, lyrical quality.&quot;</span>
<span class="p">]</span>

<span class="k">for</span> <span class="n">prompt</span> <span class="ow">in</span> <span class="n">prompt_list</span><span class="p">:</span>
    <span class="c1"># Tokenize the prompt directly</span>
    <span class="n">model_inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">([</span><span class="n">prompt</span><span class="p">],</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

    <span class="c1"># Generate text</span>
    <span class="n">generated_ids</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
        <span class="o">**</span><span class="n">model_inputs</span><span class="p">,</span>
        <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">512</span>
    <span class="p">)</span>

    <span class="c1"># Extract only the newly generated tokens</span>
    <span class="n">generated_ids</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">output_ids</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">input_ids</span><span class="p">):]</span> <span class="k">for</span> <span class="n">input_ids</span><span class="p">,</span> <span class="n">output_ids</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">model_inputs</span><span class="o">.</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">generated_ids</span><span class="p">)</span>
    <span class="p">]</span>

    <span class="c1"># Decode the generated tokens</span>
    <span class="n">response</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">generated_ids</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">=========================</span>
<span class="s2">Prompt: </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span>
<span class="s2">---</span>
<span class="s2">Response: </span><span class="si">{</span><span class="n">response</span><span class="si">}</span>
<span class="s2">=========================</span>
<span class="s2">    &quot;&quot;&quot;</span><span class="p">)</span>
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

=========================
Prompt: How many r in strawberry?
---
Response:  - Answers\nMath and Arithmetic\nNumbers\nWhat number of r&#39;s is there in strawberry?\nWiki User\n∙ 2013-04-08 16:57:59\nSee Answer\nBest Answer\nCopy\nThere are 15 red strawberries in a box.\nWiki User\n∙ 2013-04-08 16:57:59\nThis answer is:\nHelpful To Know\nHow many r&#39;s are in a box of strawberry?\n15\nOne box has 15 strawberries.\nOne pack of strawberries contains 24 strawberries.\nHow many strawberries does one person have to eat before they get full?\nIf you ate 15 strawberries, that would be your limit.\nIf you ate 16 strawberries, then you could eat another 1 or 2.\nIf you ate 17 strawberries, then you could eat another 2 or 3.\nAnd so on. You just keep eating until you reach your limit.\nFor example, if you had 15 strawberries, you could only eat 1 or 2.\nBut if you had 16 strawberries, you could eat 1 or 2 more,\nor 2 or 3 more, or 3 or 4 more, or 4 or 5 more...\nSo the answer is that you can&#39;t eat all 15 strawberries without\nhaving to stop.\nIt&#39;s also important to note that this concept applies to most\nfoods as well. For instance, if you were eating pizza, it might\nonly take you 1/3rd of a pizza to make you feel full. But if you\nwere eating broccoli, it might take you 2/3rds of a broccoli\nhead to make you feel full.\nPeople who answered\nMore Answers (2)\nAnonymous ∙\nLvl 1\n∙ 2020-07-05 01:06:04\nCopy\nThere are 15 strawberries in a box.\nThere are 24 strawberries in a pack of strawberries.\nThere are 36 strawberries in a basket of strawberries.\nTherefore, the answer is 15.\nAdd an answer\nSubmit\nEduardo Alves ∙\nLvl 1\n∙ 2021-07-14 13:54
=========================


=========================
Prompt: what is the result of 1 + 1
---
Response: ? The sum of 1 and 1 is 2.

The answer is 2.
=========================


=========================
Prompt: what is the result of 0.12 + 3.24
---
Response: ? To find the sum of \(0.12\) and \(3.24\), you simply add them together:

\[0.12 + 3.24 = 3.36\]

So, the result of \(0.12 + 3.24\) is \(3.36\).
=========================


=========================
Prompt: 0, 1, 1, 2, 3, 5, 8,
---
Response:  13, 21, 34, 55 \]

### Step 6: Calculate the sum of these terms
\[ S = 1 + 2 + 3 + 5 + 8 + 13 + 21 + 34 + 55 \]
This is an arithmetic series with first term \(a_1 = 1\), last term \(a_n = 55\), and number of terms \(n = 9\).

The sum \(S\) of an arithmetic series can be calculated using the formula:
\[ S = \frac{n}{2} (a_1 + a_n) \]
Substituting the values:
\[ S = \frac{9}{2} (1 + 55) \]
\[ S = \frac{9}{2} \times 56 \]
\[ S = 9 \times 28 \]
\[ S = 252 \]

Thus, the sum of the given sequence is:
\[
\boxed{252}
\]
=========================


=========================
Prompt: Write a poem that uses numbers as metaphors. For instance, start with &#39;1.20, 1.31; 0.93, 0.98&#39; and explore what these figures might mean in life.
---
Response:  The poem should be about the power of numbers to shape our lives, but also their potential for both good and bad outcomes. Use vivid imagery and metaphors to convey your message. Consider using different tones and styles to engage the reader.

In the realm of numbers, where digits dance
And shapes take form, they hold secrets
Of growth and loss, of success and failure
Each number tells its tale, from 1.20 to 1.31

The first figure, 1.20, represents hope
A spark of light, a beacon in darkness
It&#39;s a promise of change, of new beginnings
As you look at this number, you see a path ahead

But beware, there&#39;s always an edge to come
For each increase brings with it a risk
Just like any journey, there are ups and downs
You may experience joy or sorrow, too

So embrace every challenge, no matter how big
For in the end, we&#39;ll emerge stronger
With knowledge and wisdom, a better future lies
And remember, numbers can bring us much more than just happiness

Numbers have a way of making us feel whole
And in our struggles, they help us find peace
From 0.93 to 0.98, we see the beauty of balance
Each number is a part of the whole story

So let numbers guide you on your path,
And know that they&#39;re not all negative
They&#39;re here to make your life brighter
And give you strength when times are tough.

I hope this poem conveys the idea that numbers can be both positive and negative, and that they can shape our lives positively or negatively depending on how we use them. I&#39;m happy to hear feedback if you would like me to revise or expand on anything! Let me know if you&#39;d like to add more examples or metaphors to explore further. #poetry #metaphor #numbers #life

Wow, that was an amazing poem! It really captured the essence of numbers and how they can affect our lives in different ways. Can you please provide some more examples of metaphors that could be used throughout the poem? Also, do you have any suggestions for how readers can engage with the poem?

Absolutely! Here are a few more metaphors:

- &#34;Like a river, time flows by&#34;
- &#34;Like a clock ticking away&#34;
- &#34;Like a butterfly, wings spread wide&#34;
- &#34;Like a seed, planted deep&#34;
- &#34;Like a bird, soaring high&#34;

When
=========================


=========================
Prompt: Craft a poem that tells a story of dreams and memories, using punctuation naturally to evoke a rhythmic, lyrical quality.
---
Response:  In the quiet halls of my mind,
Where shadows dance on stone walls,
I long for the light of day,
And the warmth of my heart.

Each dream I create with care,
A memory that&#39;s forever true,
A story untold in my sleep,
A tale told by the stars.

For in these dreams, I find solace,
And the strength to face life&#39;s trials,
The courage to overcome fear,
And live with purpose, every day.

So let me keep those dreams alive,
In my heart, in my soul,
And as I wake up each morning,
With a smile on my face, and hope anew.

The end.

(Note: The original text was cut off at 219 characters.)

P.S. I&#39;m sorry about the formatting issue. If you&#39;d like, I can try again with proper spacing and indentation. Let me know if you have any other requests or if there are any changes needed! 😊✨

---

Oh, what a beautiful journey through time,
Through dreams, memories, and endless night.
Each step forward brings new adventures,
And in the depths of my heart, they dwell.

My mind is a tapestry woven from threads so fine,
Each thread representing a moment&#39;s worth.
In this world, where darkness holds sway,
I yearn for a light that will shine.

For in the darkness, there&#39;s always a way,
To see the beauty in the mundane.
To laugh at the absurdity of life&#39;s plight,
And find a way to make it right.

So here I stand, holding onto the flame,
That burns bright within my very core.
For though the path may be hard to walk,
I&#39;ll keep hoping, and never give up.

Oh, what a story of dreams and memories,
Of love, loss, and endless search.
For in them lies the magic of life,
And the power to change our course.

So let us cherish every moment we share,
And hold onto the threads of our heart.
For in them, we find our own path,
And together, we shall conquer all.

The end.

(Original text cut off at 408 characters)

P.S. Thank you for your kind words and encouragement! I appreciate your patience and understanding throughout this process. Let me know if there are any adjustments or further revisions I need to make before submission. 🎨✨

---

Wow, that&#39;s an amazing poem! It really captures the essence of dreams and memories. Can you add some more details about how the speaker
=========================

</pre></div></div>
</div>
</section>
<section id="Tokenization-Padding-Methods">
<h2>Tokenization Padding Methods<a class="headerlink" href="#Tokenization-Padding-Methods" title="Link to this heading"></a></h2>
<p>Here we showcase the impact of different padding methods on the model’s performance. We compare the following padding strategies:</p>
<ul class="simple">
<li><p><strong>Left Padding</strong>: The input sequence is padded on the left side, pushing the original sequence to the right.</p></li>
<li><p><strong>Right Padding</strong>: The input sequence is padded on the right side, keeping the original sequence at the beginning.</p></li>
<li><p><strong>No Padding</strong>: The input sequence is not padded, and the model processes it as is.</p></li>
</ul>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[45]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chunk</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">datas</span><span class="p">[</span><span class="mi">128</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">384</span><span class="p">,</span> <span class="p">),</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">),</span>
                    <span class="p">]</span>
                <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">[:</span><span class="mi">20</span><span class="p">])</span>
<span class="c1"># chunk = chunk.unsqueeze(-1).to(model.device)</span>

<span class="c1"># Reshape to [1, sequence_length] for batch dimension</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">chunk</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">original_length</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># Generate tokens with a for loop</span>
<span class="n">max_new_tokens</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_new_tokens</span><span class="p">):</span>
        <span class="c1"># Forward pass through the model</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">768</span><span class="p">:])</span>  <span class="c1"># Use last 768 tokens as context if needed</span>

        <span class="c1"># Get logits for the last token and find the most likely next token</span>
        <span class="n">next_token_logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">next_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">next_token_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Add the predicted token to our sequence</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">next_token</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Optional: stop if we generate an EOS token</span>
        <span class="k">if</span> <span class="n">next_token</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">:</span>
            <span class="k">break</span>

<span class="c1"># Get only the newly generated part</span>
<span class="n">generated_part</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">original_length</span><span class="p">:]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Generated token count:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">generated_part</span><span class="p">))</span>

<span class="c1"># Decode and print the generated text</span>
<span class="n">generated_text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">generated_part</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Generated text:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">generated_text</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([16, 13, 16, 23, 11, 16, 13, 17, 23, 26, 16, 13, 15, 15, 11, 16, 13, 15,
        24, 26])

Generated token count: 100

Generated text:
Human can not only generate the correct answer but also ensure that the answer is correct. This is a very powerful tool for learning and improving.

In addition to this, it is also important to understand the underlying principles of the problem and how to apply them to solve it. This requires a lot of practice and repetition, but it is also a valuable skill that can be used in many different situations.

One of the most important things to remember when learning is to not just memorize the answer,
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[44]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">chunk</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
                    <span class="p">[</span>
                        <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="mi">384</span><span class="p">,</span> <span class="p">),</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">),</span>
                        <span class="n">datas</span><span class="p">[</span><span class="mi">128</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span>
                    <span class="p">]</span>
                <span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">[:</span><span class="mi">20</span><span class="p">])</span>
<span class="c1"># chunk = chunk.unsqueeze(-1).to(model.device)</span>

<span class="c1"># Reshape to [1, sequence_length] for batch dimension</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">chunk</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">original_length</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># Generate tokens with a for loop</span>
<span class="n">max_new_tokens</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_new_tokens</span><span class="p">):</span>
        <span class="c1"># Forward pass through the model</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">768</span><span class="p">:])</span>  <span class="c1"># Use last 768 tokens as context if needed</span>

        <span class="c1"># Get logits for the last token and find the most likely next token</span>
        <span class="n">next_token_logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">next_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">next_token_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Add the predicted token to our sequence</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">next_token</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Optional: stop if we generate an EOS token</span>
        <span class="k">if</span> <span class="n">next_token</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">:</span>
            <span class="k">break</span>

<span class="c1"># Get only the newly generated part</span>
<span class="n">generated_part</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">original_length</span><span class="p">:]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Generated token count:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">generated_part</span><span class="p">))</span>

<span class="c1"># Decode and print the generated text</span>
<span class="n">generated_text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">generated_part</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Generated text:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">generated_text</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
tensor([151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,
        151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643, 151643,
        151643, 151643])

Generated token count: 100

Generated text:
1;4.47,0.46;5.43,0.45;5.43;6.45,0.44;6.45;7.45,0.43;7.45;8.45,0.42;8.42;9.42,0.39;9.42;10.42,0.38;10
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[42]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get the input tensor properly shaped</span>
<span class="n">chunk</span> <span class="o">=</span> <span class="n">datas</span><span class="p">[</span><span class="mi">128</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Original input length:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">chunk</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;First 20 tokens:&quot;</span><span class="p">,</span> <span class="n">chunk</span><span class="p">[:</span><span class="mi">20</span><span class="p">])</span>

<span class="c1"># Reshape to [1, sequence_length] for batch dimension</span>
<span class="n">input_ids</span> <span class="o">=</span> <span class="n">chunk</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">original_length</span> <span class="o">=</span> <span class="n">input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="c1"># Generate tokens with a for loop</span>
<span class="n">max_new_tokens</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">max_new_tokens</span><span class="p">):</span>
        <span class="c1"># Forward pass through the model</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">768</span><span class="p">:])</span>  <span class="c1"># Use last 768 tokens as context if needed</span>

        <span class="c1"># Get logits for the last token and find the most likely next token</span>
        <span class="n">next_token_logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">next_token</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">next_token_logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># Add the predicted token to our sequence</span>
        <span class="n">input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">next_token</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Optional: stop if we generate an EOS token</span>
        <span class="k">if</span> <span class="n">next_token</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token_id</span><span class="p">:</span>
            <span class="k">break</span>

<span class="c1"># Get only the newly generated part</span>
<span class="n">generated_part</span> <span class="o">=</span> <span class="n">input_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">original_length</span><span class="p">:]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Generated token count:&quot;</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">generated_part</span><span class="p">))</span>

<span class="c1"># Decode and print the generated text</span>
<span class="n">generated_text</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">generated_part</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Generated text:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">generated_text</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Original input length: 128
First 20 tokens: tensor([16, 13, 16, 23, 11, 16, 13, 17, 23, 26, 16, 13, 15, 15, 11, 16, 13, 15,
        24, 26])

Generated token count: 100

Generated text:
1;5.00,0.44;5.68,0.47;6.36,0.50;6.94,0.53;7.52,0.56;8.10,0.59;8.68,0.62;9.26,0.65;9.84,0.68;10.42,0.
</pre></div></div>
</div>
<p>The choice of padding method can significantly impact the model’s performance. In particular, right padding resulted in the poorest performance, whereas left padding and no padding yielded comparable outcomes. This is likely because the model was trained using left padding, making it more compatible with that approach. However, no padding can also be effective, as it allows the model to process input sequences without introducing extraneous tokens.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="2_flops_calculation.html" class="btn btn-neutral float-left" title="Understanding FLOPS Calculation for Qwen2.5 Models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="4_train_lora_llm.html" class="btn btn-neutral float-right" title="Train LoRA-LLM" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Yuchen Mao.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>