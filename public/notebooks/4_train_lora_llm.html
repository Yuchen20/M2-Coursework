

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Train LoRA-LLM &mdash; Time Series Forecasting with LLMs beta documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css?v=2aa19091" />
      <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=a6e103b4" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=f0d2c090"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
      <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Evaluating Trained LLM Performance on Time Series Forecasting" href="5_initial_train_behaviour.html" />
    <link rel="prev" title="Evaluating Untrained LLM Performance on Time Series Forecasting" href="3_untrained_behaviour.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Time Series Forecasting with LLMs
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Jupyter Notebooks</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="1_dataset_preprocess.html">Lotka-Volterra Dataset Exploration &amp; LLMTIME Preprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="2_flops_calculation.html">Understanding FLOPS Calculation for Qwen2.5 Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="3_untrained_behaviour.html">Evaluating Untrained LLM Performance on Time Series Forecasting</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Train LoRA-LLM</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Improved-LoRA-Training">Improved LoRA Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Training-the-Model">Training the Model</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="5_initial_train_behaviour.html">Evaluating Trained LLM Performance on Time Series Forecasting</a></li>
<li class="toctree-l1"><a class="reference internal" href="6_fully_trained_behaviour.html">Evaluating Fully Trained LLM Performance on Time Series Forecasting</a></li>
<li class="toctree-l1"><a class="reference internal" href="6_fully_trained_behaviour.html#Flops-Analysis">Flops Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="7_weight_visualize.html">LM Bias Weight Visualization</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Time Series Forecasting with LLMs</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Train LoRA-LLM</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/notebooks/4_train_lora_llm.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <div class="admonition note">
<p class="admonition-title">Note</p>
<p>This page was generated from a Jupyter notebook.
<a class="reference external" href="https://github.com/yourusername/time_series_llm/blob/main/notebooks4_train_lora_llm.ipynb">View the original notebook</a></p>
</div>
<section id="Train-LoRA-LLM">
<h1>Train LoRA-LLM<a class="headerlink" href="#Train-LoRA-LLM" title="Link to this heading"></a></h1>
<p>This is a tutorial notebook on how to train a Qwen model with LoRA using our <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> class.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># %%</span>

<span class="c1"># Imports</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">torch.nn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">torch.utils.data</span><span class="w"> </span><span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">transformers</span><span class="w"> </span><span class="kn">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">gc</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">wandb</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">h5py</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="vm">__name__</span><span class="p">),</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">pardir</span><span class="p">)))</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">src.get_flops</span><span class="w"> </span><span class="kn">import</span> <span class="n">QwenFlopsCalculator</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">src.get_data</span><span class="w"> </span><span class="kn">import</span> <span class="n">LotkaVolterraDataset</span><span class="p">,</span> <span class="n">DataMaster</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">src.preprocessor</span><span class="w"> </span><span class="kn">import</span> <span class="n">NumericalProcessor</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">sys</span>
<span class="n">sys</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">abspath</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="vm">__name__</span><span class="p">),</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">pardir</span><span class="p">)))</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">src.Trainer</span><span class="w"> </span><span class="kn">import</span> <span class="n">LoRATrainer</span>

<span class="c1"># models</span>
<span class="k">def</span><span class="w"> </span><span class="nf">load_qwen</span><span class="p">():</span>
    <span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;Qwen/Qwen2.5-0.5B-Instruct&quot;</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="c1"># Freeze all parameters except LM head bias</span>
    <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
        <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="c1"># Add trainable bias to logits</span>
    <span class="k">assert</span> <span class="n">model</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="kc">None</span>
    <span class="n">model</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">lm_head</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span>


<span class="c1"># some nice function for GPU Training</span>
<span class="k">def</span><span class="w"> </span><span class="nf">clear_memory</span><span class="p">():</span>
    <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">):</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">empty_cache</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">ipc_collect</span><span class="p">()</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">reset_peak_memory_stats</span><span class="p">()</span>

<span class="c1"># device</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

<span class="c1"># random seed</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
<section id="Improved-LoRA-Training">
<h2>Improved LoRA Training<a class="headerlink" href="#Improved-LoRA-Training" title="Link to this heading"></a></h2>
<p>Here we have the LoRALinear class with a slight modification to allow for the merging of LoRA into the original model. A key benefit of LoRA compared to other parameter-efficient tuning methods is that it allows for the merging of the LoRA weights into the original model weights. This means that after training, the model can be used without the LoRA adapter, which can save memory and improve inference speed. The merging process involves adding the LoRA weights to the original model weights in a
way that preserves the original model’s performance while also incorporating the new knowledge learned during training.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><br/><br/><span></span><span class="c1"># LoRA implementation</span>
<span class="k">class</span><span class="w"> </span><span class="nc">LoRALinear</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">original_linear</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">,</span> <span class="n">r</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">alpha</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">original_linear</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">original_linear</span> <span class="o">=</span> <span class="n">original_linear</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">original_linear</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_linear</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">original_linear</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">in_dim</span> <span class="o">=</span> <span class="n">original_linear</span><span class="o">.</span><span class="n">in_features</span>
        <span class="n">out_dim</span> <span class="o">=</span> <span class="n">original_linear</span><span class="o">.</span><span class="n">out_features</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">r</span> <span class="o">=</span> <span class="n">r</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span> <span class="k">if</span> <span class="n">alpha</span> <span class="k">else</span> <span class="n">r</span>

        <span class="n">device</span> <span class="o">=</span> <span class="n">original_linear</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">device</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">in_dim</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">B</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">out_dim</span><span class="p">,</span> <span class="n">r</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>

        <span class="c1"># Initialise A with He initialization</span>
        <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">merged_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_linear</span><span class="o">.</span><span class="n">weight</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_merged</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">is_merged</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">merged_weight</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_linear</span><span class="o">.</span><span class="n">bias</span><span class="p">)</span>

        <span class="n">base_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">lora_out</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">A</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="o">.</span><span class="n">T</span>
        <span class="k">return</span> <span class="n">base_out</span> <span class="o">+</span> <span class="n">lora_out</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">r</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">merge</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">merged_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_linear</span><span class="o">.</span><span class="n">weight</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">A</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="o">.</span><span class="n">T</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">r</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_merged</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">unmerge</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">is_merged</span> <span class="o">=</span> <span class="kc">False</span>


<span class="n">model</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">load_qwen</span><span class="p">()</span>

<span class="c1"># before applying LoRA, we need to freeze the model</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

<span class="n">lora_rank</span> <span class="o">=</span> <span class="mi">4</span>

<span class="c1"># Actually apply LoRA to the model:</span>
<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
    <span class="n">layer</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">q_proj</span> <span class="o">=</span> <span class="n">LoRALinear</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">q_proj</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="n">lora_rank</span><span class="p">)</span>
    <span class="n">layer</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">v_proj</span> <span class="o">=</span> <span class="n">LoRALinear</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">self_attn</span><span class="o">.</span><span class="n">v_proj</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="n">lora_rank</span><span class="p">)</span>


<span class="c1"># now lets check what weights are trainable to confirm that the LoRA has been applied</span>
<span class="n">trainable_params</span> <span class="o">=</span> <span class="p">[</span><span class="n">n</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Here, we showcase few of the trainable parameters: </span><span class="si">{</span><span class="n">trainable_params</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Here, we showcase few of the trainable parameters: [&#39;model.layers.0.self_attn.q_proj.A&#39;, &#39;model.layers.0.self_attn.q_proj.B&#39;, &#39;model.layers.0.self_attn.v_proj.A&#39;, &#39;model.layers.0.self_attn.v_proj.B&#39;, &#39;model.layers.1.self_attn.q_proj.A&#39;]
</pre></div></div>
</div>
<p>Here we load in the data</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># data folder:</span>
<span class="n">DATA_FOLDER</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">dirname</span><span class="p">(</span><span class="vm">__name__</span><span class="p">),</span> <span class="s1">&#39;..&#39;</span><span class="p">,</span> <span class="s1">&#39;data&#39;</span><span class="p">)</span>


<span class="k">with</span> <span class="n">h5py</span><span class="o">.</span><span class="n">File</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">DATA_FOLDER</span><span class="p">,</span> <span class="s1">&#39;lotka_volterra_data.h5&#39;</span><span class="p">),</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="c1"># Access the full dataset</span>
    <span class="n">trajectories</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="s2">&quot;trajectories&quot;</span><span class="p">][:]</span>
    <span class="n">time_points</span> <span class="o">=</span> <span class="n">f</span><span class="p">[</span><span class="s2">&quot;time&quot;</span><span class="p">][:]</span>

<span class="c1"># Here we are only using a small fraction of the data for the experiment</span>
<span class="n">data_master</span> <span class="o">=</span> <span class="n">DataMaster</span><span class="p">(</span>
    <span class="n">tokenizer</span><span class="p">,</span> <span class="n">trajectories</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">val_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">experiment_fraction</span><span class="o">=</span><span class="mf">0.02</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Training-the-Model">
<h2>Training the Model<a class="headerlink" href="#Training-the-Model" title="Link to this heading"></a></h2>
<p>We now proceed to train the model. For demonstration purposes, we only run a few epochs, but increasing the number of epochs can lead to better performance. This example illustrates how to train a model with LoRA using the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> class. It also serves as an opportunity to test and validate the custom <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> class implementation.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># import lib reload loraTrainer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">importlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">reload</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">src.Trainer</span>
<span class="n">reload</span><span class="p">(</span><span class="n">src</span><span class="o">.</span><span class="n">Trainer</span><span class="p">)</span>

<span class="c1"># tqdm clear process</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">tqdm</span><span class="w"> </span><span class="kn">import</span> <span class="n">tqdm</span>
<span class="n">tqdm</span><span class="o">.</span><span class="n">_instances</span><span class="o">.</span><span class="n">clear</span><span class="p">()</span>


<span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">test_loader</span> <span class="o">=</span> <span class="n">data_master</span><span class="o">.</span><span class="n">get_data</span><span class="p">(</span><span class="n">experiment</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">target_eval_pairs</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">context_length</span><span class="o">=</span><span class="mi">512</span><span class="p">)</span>


<span class="n">trainer</span> <span class="o">=</span> <span class="n">LoRATrainer</span><span class="p">(</span>
    <span class="n">model</span><span class="p">,</span> <span class="n">train_loader</span><span class="o">=</span><span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="o">=</span><span class="n">val_loader</span><span class="p">,</span> <span class="n">test_loader</span><span class="o">=</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">processor</span> <span class="o">=</span> <span class="n">data_master</span><span class="o">.</span><span class="n">processor</span><span class="p">,</span>
    <span class="n">lora_rank</span> <span class="o">=</span>  <span class="mi">4</span><span class="p">,</span> <span class="n">context_length</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span> <span class="n">eval_interval</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">save_interval</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">max_steps</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
    <span class="p">)</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Prepared 8 inference samples with max target length 490
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>

</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Prepared 4 inference samples with max target length 478
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Sanity check Train: 100%|██████████| 7/7 [00:00&lt;00:00, 208.68it/s]
Sanity check Val: 100%|██████████| 4/4 [00:00&lt;00:00, 4004.11it/s]
Sanity check Test: 100%|██████████| 2/2 [00:00&lt;00:00, 1990.18it/s]
<span class="ansi-blue-intense-fg ansi-bold">wandb</span>: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
<span class="ansi-blue-intense-fg ansi-bold">wandb</span>: Currently logged in as: <span class="ansi-yellow-fg">ym429</span> (<span class="ansi-yellow-fg">ym429-university-of-cambridge</span>) to <span class="ansi-green-fg">https://api.wandb.ai</span>. Use <span class="ansi-bold">`wandb login --relogin`</span> to force relogin
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
Tracking run with wandb version 0.19.8</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
Run data is saved locally in <code>c:\Users\yuche\OneDrive\Documents\Brain in a vat\CAM Mphil\Lent\CourseWork\M2 Course Work\notebooks\wandb\run-20250321_193006-axomsmwz</code></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
Syncing run <strong><a href='https://wandb.ai/ym429-university-of-cambridge/M2-Course-Work/runs/axomsmwz' target="_blank">lora-r4-lr1e-04-20250321_193006</a></strong> to <a href='https://wandb.ai/ym429-university-of-cambridge/M2-Course-Work' target="_blank">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target="_blank">docs</a>)<br></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
View project at <a href='https://wandb.ai/ym429-university-of-cambridge/M2-Course-Work' target="_blank">https://wandb.ai/ym429-university-of-cambridge/M2-Course-Work</a></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area rendered_html docutils container">
View run at <a href='https://wandb.ai/ym429-university-of-cambridge/M2-Course-Work/runs/axomsmwz' target="_blank">https://wandb.ai/ym429-university-of-cambridge/M2-Course-Work/runs/axomsmwz</a></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Total trainable parameters: 270,336
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Validation:   0%|          | 0/4 [00:00&lt;?, ?it/s]it/s, ce=0.5047, steps9, loss=0.5047]<span class="ansi-blue-intense-fg ansi-bold">wandb</span>: <span class="ansi-yellow-fg">WARNING</span> Tried to log to step 1 that is less than the current step 2. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
<span class="ansi-blue-intense-fg ansi-bold">wandb</span>: <span class="ansi-yellow-fg">WARNING</span> Tried to log to step 1 that is less than the current step 2. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
<span class="ansi-blue-intense-fg ansi-bold">wandb</span>: <span class="ansi-yellow-fg">WARNING</span> Tried to log to step 1 that is less than the current step 2. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
<span class="ansi-blue-intense-fg ansi-bold">wandb</span>: <span class="ansi-yellow-fg">WARNING</span> Tried to log to step 1 that is less than the current step 2. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.

Validation:  25%|██▌       | 1/4 [00:05&lt;00:17,  5.80s/it]

Validation:  50%|█████     | 2/4 [00:11&lt;00:11,  5.84s/it]

Validation:  75%|███████▌  | 3/4 [00:18&lt;00:06,  6.21s/it]



</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Validation on 8 samples - MSE: 0.05341527611017227, MAE: 0.15549632906913757, Failure rate: 0.0%, Speed: 12.00 tokens/sec
Saved checkpoint to checkpoints\checkpoint_best.pth
New best model with val loss: 1.4418
Saved checkpoint to checkpoints\checkpoint_step_10.pth
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Validation:   0%|          | 0/4 [00:00&lt;?, ?it/s]7it/s, ce=0.5343, steps19, loss=0.5343]
Validation:  25%|██▌       | 1/4 [00:05&lt;00:17,  5.81s/it]

Validation:  50%|█████     | 2/4 [00:11&lt;00:11,  5.97s/it]

Validation:  75%|███████▌  | 3/4 [00:18&lt;00:06,  6.18s/it]



</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Validation on 8 samples - MSE: 0.07991088926792145, MAE: 0.1819341778755188, Failure rate: 0.0%, Speed: 12.18 tokens/sec
Saved checkpoint to checkpoints\checkpoint_step_20.pth
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Validation:   0%|          | 0/4 [00:00&lt;?, ?it/s]
Validation:  25%|██▌       | 1/4 [00:07&lt;00:21,  7.14s/it]

Validation:  50%|█████     | 2/4 [00:14&lt;00:14,  7.03s/it]

Validation:  75%|███████▌  | 3/4 [00:21&lt;00:07,  7.34s/it]



</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Validation on 8 samples - MSE: 0.07991088926792145, MAE: 0.1819341778755188, Failure rate: 0.0%, Speed: 10.38 tokens/sec
Loading best checkpoint from checkpoints\checkpoint_best.pth for final testing
Warning: Loading checkpoint with weights_only=False due to: Weights only load failed. This file can still be loaded, to do so you have two options, <span class="ansi-bold">do those steps only if you trust the source of the checkpoint</span>.
        (1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.
        (2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.
        WeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.

Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.
Loaded checkpoint from checkpoints\checkpoint_best.pth (step 10)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
Test:   0%|          | 0/2 [00:00&lt;?, ?it/s]
Test:  50%|█████     | 1/2 [00:06&lt;00:06,  6.82s/it]



</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

Test on 4 samples - MSE: 0.03215603902935982, MAE: 0.11131727695465088, Failure rate: 0.0%, Speed: 11.60 tokens/sec
Saved checkpoint to checkpoints\checkpoint_final.pth
Training completed in 10 steps
Best validation loss: 1.4418
Final validation loss: 1.4612
Test MSE: 0.0322, Test MAE: 0.1113
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
<span class="ansi-blue-intense-fg ansi-bold">wandb</span>: <span class="ansi-yellow-fg">WARNING</span> Tried to log to step 10 that is less than the current step 20. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
<span class="ansi-blue-intense-fg ansi-bold">wandb</span>: <span class="ansi-yellow-fg">WARNING</span> Tried to log to step 10 that is less than the current step 20. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
<span class="ansi-blue-intense-fg ansi-bold">wandb</span>: <span class="ansi-yellow-fg">WARNING</span> Tried to log to step 10 that is less than the current step 20. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="3_untrained_behaviour.html" class="btn btn-neutral float-left" title="Evaluating Untrained LLM Performance on Time Series Forecasting" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="5_initial_train_behaviour.html" class="btn btn-neutral float-right" title="Evaluating Trained LLM Performance on Time Series Forecasting" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Yuchen Mao.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>